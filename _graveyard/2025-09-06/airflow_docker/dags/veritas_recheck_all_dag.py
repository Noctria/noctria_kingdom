# airflow_docker/dags/veritas_recheck_all_dag.py
# -*- coding: utf-8 -*-
"""
ğŸ” Veritas ä¸€æ‹¬å†è©•ä¾¡ DAG
- GUI (/pdca/recheck_all) ã‹ã‚‰ã® conf ã‚’å—ã‘å–ã‚Šã€filters ã«åŸºã¥ãå¯¾è±¡æˆ¦ç•¥ã‚’æŠ½å‡º
- å€‹åˆ¥å†è©•ä¾¡DAGï¼ˆveritas_recheck_dagï¼‰ã‚’ TriggerDagRunOperator ã§ä¸¦åˆ—èµ·å‹•
- ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯ conf = {"filters": {...}, "reason": "...", "triggered_by": "GUI"} ã‚’æƒ³å®š

ä¾å­˜:
- Airflow 2.5+ï¼ˆTask Mappingä½¿ç”¨ï¼‰
- å€‹åˆ¥å†è©•ä¾¡DAG: ç’°å¢ƒå¤‰æ•° AIRFLOW_DAG_RECHECK ã§æŒ‡å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: "veritas_recheck_dag"ï¼‰
"""

from __future__ import annotations

import json
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional

import pandas as pd
from airflow import DAG
from airflow.decorators import task
from airflow.operators.trigger_dagrun import TriggerDagRunOperator

# ==== è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯ï¼‰ ==========================================
PROJECT_ROOT = Path(__file__).resolve().parents[2]  # <repo_root>
PDCA_LOG_DIR = PROJECT_ROOT / "data" / "pdca_logs" / "veritas_orders"
STRATEGIES_DIR = PROJECT_ROOT / "src" / "strategies"

DAG_ID_RECHECK_ALL = os.getenv("AIRFLOW_DAG_RECHECK_ALL", "veritas_recheck_all_dag")
DAG_ID_RECHECK_SINGLE = os.getenv("AIRFLOW_DAG_RECHECK", "veritas_recheck_dag")

DEFAULT_ARGS = {
    "owner": "noctria",
    "depends_on_past": False,
    "retries": 0,
}

# ==== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ======================================================
def _safe_to_float(x) -> Optional[float]:
    try:
        if x is None or (isinstance(x, float) and pd.isna(x)):
            return None
        return float(x)
    except Exception:
        return None

def _load_pdca_logs() -> pd.DataFrame:
    """
    PDCAãƒ­ã‚°ï¼ˆCSV/JSONè¤‡æ•°ï¼‰ã‚’ç¸¦çµåˆã—ã¦æ¨™æº–åˆ—ã‚’è£œå®Œã€‚
    """
    if not PDCA_LOG_DIR.exists():
        return pd.DataFrame()

    frames: List[pd.DataFrame] = []
    for fname in sorted(PDCA_LOG_DIR.iterdir()):
        if not fname.is_file():
            continue
        try:
            if fname.suffix.lower() == ".csv":
                df = pd.read_csv(fname)
            elif fname.suffix.lower() == ".json":
                obj = json.loads(fname.read_text())
                df = pd.DataFrame(obj if isinstance(obj, list) else [obj])
            else:
                continue
            df["__source_file"] = fname.name
            frames.append(df)
        except Exception:
            # å£Šã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—
            continue

    if not frames:
        return pd.DataFrame()

    df_all = pd.concat(frames, ignore_index=True)

    # å¿…é ˆåˆ—ã®è£œå®Œ
    for col in [
        "strategy", "evaluated_at",
        "winrate_old", "winrate_new",
        "maxdd_old", "maxdd_new",
        "trades_old", "trades_new",
        "tag", "notes",
    ]:
        if col not in df_all.columns:
            df_all[col] = None

    # å‹ãƒ»å·®åˆ†
    df_all["evaluated_at"] = pd.to_datetime(df_all["evaluated_at"], errors="coerce")
    for col in ["winrate_old", "winrate_new", "maxdd_old", "maxdd_new"]:
        df_all[col] = df_all[col].apply(_safe_to_float)

    df_all["winrate_diff"] = df_all.apply(
        lambda r: None
        if (r["winrate_old"] is None or r["winrate_new"] is None)
        else (r["winrate_new"] - r["winrate_old"]),
        axis=1,
    )
    df_all["maxdd_diff"] = df_all.apply(
        lambda r: None
        if (r["maxdd_old"] is None or r["maxdd_new"] is None)
        else (r["maxdd_new"] - r["maxdd_old"]),
        axis=1,
    )
    return df_all


def _apply_filters(df: pd.DataFrame, filters: Dict[str, Any]) -> pd.DataFrame:
    if df.empty:
        return df
    res = df.copy()

    # æœŸé–“
    df_from = filters.get("date_from")
    df_to = filters.get("date_to")
    if df_from:
        res = res[res["evaluated_at"] >= pd.to_datetime(df_from, errors="coerce")]
    if df_to:
        res = res[res["evaluated_at"] <= pd.to_datetime(df_to, errors="coerce") + pd.Timedelta(days=1)]

    # å‹ç‡/æœ€å¤§DD
    wr_min = filters.get("winrate_diff_min")
    dd_max = filters.get("maxdd_diff_max")

    if wr_min is not None:
        try:
            wr_min = float(wr_min)
            res = res[res["winrate_diff"].fillna(-1e9) >= wr_min]
        except Exception:
            pass

    if dd_max is not None:
        try:
            dd_max = float(dd_max)
            # æ”¹å–„ï¼ˆã‚ˆã‚Šå°ã•ã„ = è‰¯ã„ï¼‰ã‚’æ‹¾ã†ã«ã¯ <=
            res = res[res["maxdd_diff"].fillna(1e9) <= dd_max]
        except Exception:
            pass

    # search
    s = (filters.get("search") or "").strip().lower()
    if s:
        for col in ["strategy", "tag", "notes", "__source_file"]:
            res[col] = res[col].astype(str)
        res = res[
            res["strategy"].str.lower().str.contains(s, na=False)
            | res["tag"].str.lower().str.contains(s, na=False)
            | res["notes"].str.lower().str.contains(s, na=False)
            | res["__source_file"].str.lower().str.contains(s, na=False)
        ]
    return res


def _fallback_strategies_from_repo() -> List[str]:
    """
    ãƒ­ã‚°ãŒç„¡ã„/ç©ºã®ã¨ãã¯ src/strategies/ é…ä¸‹ã® .py ã‚’æˆ¦ç•¥å€™è£œã¨ã—ã¦è¿”ã™ã€‚
    _ ã§å§‹ã¾ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ __init__.py ã¯é™¤å¤–ã€‚
    """
    if not STRATEGIES_DIR.exists():
        return []
    names: List[str] = []
    for p in STRATEGIES_DIR.glob("*.py"):
        if p.name.startswith("_") or p.name == "__init__.py":
            continue
        names.append(p.stem)  # æ‹¡å¼µå­é™¤å»
    return sorted(set(names))


def _select_targets(conf: Dict[str, Any]) -> List[str]:
    """
    conf ã‹ã‚‰ filters ã‚’èª­ã¿ã€å¯¾è±¡æˆ¦ç•¥ã®ãƒªã‚¹ãƒˆã‚’æ±ºå®šã€‚
    - ãƒ­ã‚°ãŒã‚ã‚Œã°ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
    - ãªã‘ã‚Œã°ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰æˆ¦ç•¥ãƒ•ã‚¡ã‚¤ãƒ«åã‚’åˆ—æŒ™
    """
    filters = (conf or {}).get("filters") or {}
    df = _load_pdca_logs()
    if not df.empty:
        dff = _apply_filters(df, filters)
        strategies = (
            dff["strategy"].dropna().astype(str).str.strip().tolist()
        )
        strategies = [s for s in strategies if s]
        if strategies:
            return sorted(set(strategies))
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    return _fallback_strategies_from_repo()


# ==== DAG å®šç¾© ==============================================================
with DAG(
    dag_id=DAG_ID_RECHECK_ALL,
    default_args=DEFAULT_ARGS,
    schedule=None,
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=["noctria", "veritas", "pdca", "recheck"],
    description="GUIãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«åŸºã¥ãä¸€æ‹¬å†è©•ä¾¡ã®è¦ªDAG",
) as dag:

    @task(multiple_outputs=True)
    def read_conf(**context) -> Dict[str, Any]:
        """triggeræ™‚ã® conf ã‚’å–ã‚Šå‡ºã—ã¦è¿”ã™ï¼ˆç©ºã§ã‚‚è½ã¨ã•ãªã„ï¼‰"""
        ti = context["ti"]
        dag_run = ti.get_dagrun()
        conf = dag_run.conf or {}
        reason = conf.get("reason")
        filters = conf.get("filters", {})
        triggered_by = conf.get("triggered_by", "unknown")
        return {
            "conf": conf,
            "reason": reason,
            "filters": filters,
            "triggered_by": triggered_by,
        }

    @task
    def decide_targets(payload: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        ãƒ•ã‚£ãƒ«ã‚¿ã‹ã‚‰å¯¾è±¡æˆ¦ç•¥ã‚’æ±ºå®šã—ã€TriggerDagRunOperator ã«æ¸¡ã™ map ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’ä½œã‚‹ã€‚
        """
        conf = payload.get("conf") or {}
        reason = payload.get("reason")
        triggered_by = payload.get("triggered_by")
        strategies = _select_targets(conf)

        # TriggerDagRunOperator.expand(conf=[...]) ç”¨ã®ãƒªã‚¹ãƒˆã«æ•´å½¢
        items: List[Dict[str, Any]] = []
        for s in strategies:
            items.append(
                {
                    "strategy": s,
                    "reason": reason,
                    "triggered_by": triggered_by,
                    "parent_dag": DAG_ID_RECHECK_ALL,
                }
            )
        return items

    # Task Mapping ã§å€‹åˆ¥DAGã‚’ä¸¦åˆ—èµ·å‹•
    trigger_each = TriggerDagRunOperator.partial(
        task_id="trigger_recheck_each",
        trigger_dag_id=DAG_ID_RECHECK_SINGLE,
        reset_dag_run=False,
        wait_for_completion=False,
        poke_interval=5,
    ).expand(conf=decide_targets(read_conf()))

    # ä¾å­˜ã¯ read_conf -> decide_targets -> trigger_each
    # TaskFlowã®æˆ»ã‚Šå€¤é…ç·šã§è‡ªå‹•çš„ã«å¼µã‚‰ã‚Œã‚‹ãŸã‚æ˜ç¤ºä¾å­˜ã¯ä¸è¦
