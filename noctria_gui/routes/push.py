#!/usr/bin/env python3
# coding: utf-8

"""
ğŸ“¦ Pushæ©Ÿèƒ½çµ±åˆãƒ«ãƒ¼ãƒˆ (v2.0)
- Airflow DAGçµŒç”±ã®GitHub Pushãƒˆãƒªã‚¬ãƒ¼
- Pushãƒ­ã‚°ã®é–²è¦§ï¼æ¤œç´¢ï¼CSVå‡ºåŠ›ï¼è©³ç´°è¡¨ç¤º
"""

import logging
import json
import csv
import io
import os
from fastapi import APIRouter, Request, Query, Form, HTTPException, Depends
from fastapi.responses import HTMLResponse, StreamingResponse, JSONResponse
from fastapi.templating import Jinja2Templates
from pydantic import BaseModel
from datetime import datetime
from typing import Optional, List, Dict, Any

# --- ç‹å›½ã®åŸºç›¤ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
# âœ… ä¿®æ­£: path_config.pyã®ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã«åˆã‚ã›ã¦ã€æ­£ã—ã„å¤‰æ•°åã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.core.path_config import PUSH_LOG_DIR, NOCTRIA_GUI_TEMPLATES_DIR
# from src.noctria_gui.services import push_service # å°†æ¥çš„ã«ãƒ­ã‚¸ãƒƒã‚¯ã‚’ã‚µãƒ¼ãƒ“ã‚¹å±¤ã«åˆ†é›¢ã™ã‚‹æƒ³å®š

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - [%(levelname)s] - %(message)s')

router = APIRouter(prefix="/push", tags=["Push"])
# âœ… ä¿®æ­£: æ­£ã—ã„å¤‰æ•°åã‚’ä½¿ç”¨
templates = Jinja2Templates(directory=str(NOCTRIA_GUI_TEMPLATES_DIR))

# --- Pydanticãƒ¢ãƒ‡ãƒ«å®šç¾© ---
class DAGTriggerResponse(BaseModel):
    detail: str
    dag_run_id: Optional[str] = None
    response_body: Optional[str] = None

# --- ä¾å­˜æ€§æ³¨å…¥ï¼ˆDIï¼‰ã«ã‚ˆã‚‹ãƒ­ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®å…±é€šåŒ– ---
def get_filtered_push_logs(
    strategy: Optional[str] = Query(None),
    tag: Optional[str] = Query(None),
    start_date: Optional[str] = Query(None),
    end_date: Optional[str] = Query(None),
    keyword: Optional[str] = Query(None),
) -> List[Dict[str, Any]]:
    """ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦Pushãƒ­ã‚°ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹å…±é€šé–¢æ•°"""
    logs = []
    if not PUSH_LOG_DIR.exists():
        logging.warning(f"Pushãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {PUSH_LOG_DIR}")
        return []

    for file_path in PUSH_LOG_DIR.glob("*.json"):
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                log = json.load(f)
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯
            if strategy and strategy.lower() not in log.get("strategy", "").lower(): continue
            if tag and tag != log.get("tag", ""): continue
            if keyword and keyword.lower() not in log.get("message", "").lower(): continue
            
            log_date_str = log.get("timestamp", "")[:10]
            if start_date and log_date_str < start_date: continue
            if end_date and log_date_str > end_date: continue
            
            logs.append(log)
        except Exception as e:
            logging.error(f"Pushãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {file_path}, ã‚¨ãƒ©ãƒ¼: {e}")
            
    return logs

# --- ãƒ«ãƒ¼ãƒˆå®šç¾© ---

@router.post("/trigger", response_model=DAGTriggerResponse)
async def trigger_push_dag(strategy_name: str = Form(...)):
    """AirflowçµŒç”±ã§GitHubã«Pushã™ã‚‹DAGã‚’ãƒˆãƒªã‚¬ãƒ¼"""
    strategy_name = strategy_name.strip()
    if not strategy_name:
        raise HTTPException(status_code=400, detail="æˆ¦ç•¥åï¼ˆstrategy_nameï¼‰ãŒç©ºã§ã™ã€‚")

    dag_id = "veritas_push_dag"
    dag_run_id = f"manual_push__{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    airflow_url = os.getenv("AIRFLOW_BASE_URL", "http://airflow-webserver:8080")
    dag_trigger_url = f"{airflow_url}/api/v1/dags/{dag_id}/dagRuns"
    
    logging.info(f"DAGã€{dag_id}ã€ã®èµ·å‹•ã‚’è©¦ã¿ã¾ã™ã€‚å¯¾è±¡æˆ¦ç•¥: {strategy_name}")

    payload = {"dag_run_id": dag_run_id, "conf": {"strategy_name": strategy_name}}

    try:
        # å®Ÿéš›ã®Airflow APIå‘¼ã³å‡ºã—ï¼ˆrequestsã¯éåŒæœŸã§ãªã„ãŸã‚ã€æœ¬ç•ªã§ã¯httpxã®éåŒæœŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’æ¨å¥¨ï¼‰
        import httpx
        async with httpx.AsyncClient() as client:
            response = await client.post(
                dag_trigger_url,
                auth=(os.getenv("AIRFLOW_USERNAME", "airflow"), os.getenv("AIRFLOW_PASSWORD", "airflow")),
                json=payload,
                timeout=15
            )
            response.raise_for_status() # HTTPã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ä¾‹å¤–ã‚’ç™ºç”Ÿã•ã›ã‚‹
        
        logging.info(f"DAGãƒˆãƒªã‚¬ãƒ¼æˆåŠŸã€‚Run ID: {dag_run_id}")
        return {"detail": f"âœ… DAGãƒˆãƒªã‚¬ãƒ¼æˆåŠŸ (Run ID: {dag_run_id})", "dag_run_id": dag_run_id}

    except httpx.HTTPStatusError as e:
        logging.error(f"Airflow APIã‚¨ãƒ©ãƒ¼ (HTTP {e.response.status_code}): {e.response.text}")
        return {"detail": f"âŒ Airflowã‚¨ãƒ©ãƒ¼å¿œç­” (HTTP {e.response.status_code})", "response_body": e.response.text}
    except Exception as e:
        logging.error(f"Airflowã¸ã®é€šä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", exc_info=True)
        return {"detail": f"ğŸš¨ Airflowé€šä¿¡å¤±æ•—: {e}"}

@router.get("/history", response_class=HTMLResponse)
def view_push_history(
    request: Request,
    sort: str = Query(default="desc"),
    page: int = Query(default=1, ge=1),
    logs: List[Dict[str, Any]] = Depends(get_filtered_push_logs)
):
    """ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸPushå±¥æ­´ã‚’è¡¨ç¤ºã™ã‚‹"""
    logs.sort(key=lambda x: x.get("timestamp", ""), reverse=(sort != "asc"))
    
    tag_list = sorted({log.get("tag") for log in logs if log.get("tag")})

    total_count = len(logs)
    page_size = 50
    total_pages = max((total_count + page_size - 1) // page_size, 1)
    page = min(page, total_pages)
    start_idx = (page - 1) * page_size
    
    return templates.TemplateResponse("push_history.html", {
        "request": request,
        "logs": logs[start_idx : start_idx + page_size],
        "tag_list": tag_list,
        "total_count": total_count,
        "total_pages": total_pages,
        "current_page": page,
    })

@router.get("/export")
def export_push_history_csv(logs: List[Dict[str, Any]] = Depends(get_filtered_push_logs)):
    """ç¾åœ¨ã®ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã§Pushå±¥æ­´ã‚’CSVå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹"""
    if not logs:
        raise HTTPException(status_code=404, detail="ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¯¾è±¡ã®ãƒ­ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    output = io.StringIO()
    fieldnames = ["timestamp", "strategy", "tag", "message", "signature"]
    writer = csv.DictWriter(output, fieldnames=fieldnames, extrasaction='ignore')
    writer.writeheader()
    writer.writerows(logs)

    output.seek(0)
    filename = f"push_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    return StreamingResponse(output, media_type="text/csv", headers={
        "Content-Disposition": f"attachment; filename={filename}"
    })

@router.get("/detail/{log_timestamp}", response_class=HTMLResponse)
def push_history_detail(request: Request, log_timestamp: str):
    """ç‰¹å®šã®Pushãƒ­ã‚°ã®è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹"""
    log_path = PUSH_LOG_DIR / f"{log_timestamp}.json"
    if not log_path.exists():
        raise HTTPException(status_code=404, detail="æŒ‡å®šã•ã‚ŒãŸãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    try:
        with open(log_path, "r", encoding="utf-8") as f:
            log = json.load(f)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    return templates.TemplateResponse("push_history_detail.html", {
        "request": request,
        "log": log
    })
