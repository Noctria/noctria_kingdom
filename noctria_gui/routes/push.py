#!/usr/bin/env python3
# coding: utf-8

"""
ğŸ“¦ Pushæ©Ÿèƒ½çµ±åˆãƒ«ãƒ¼ãƒˆ
- Airflow DAGçµŒç”±ã®GitHub Pushãƒˆãƒªã‚¬ãƒ¼
- Pushãƒ­ã‚°ã®é–²è¦§ï¼æ¤œç´¢ï¼CSVå‡ºåŠ›ï¼è©³ç´°è¡¨ç¤º
"""

from fastapi import APIRouter, Request, Query, Form, HTTPException
from fastapi.responses import HTMLResponse, StreamingResponse, JSONResponse
from fastapi.templating import Jinja2Templates
from pydantic import BaseModel
from pathlib import Path
from datetime import datetime
import requests
import logging
import json
import csv
import io
import os

from core.path_config import PUSH_LOG_DIR, GUI_TEMPLATES_DIR

router = APIRouter(tags=["Pushæ©Ÿèƒ½"])
templates = Jinja2Templates(directory=str(GUI_TEMPLATES_DIR))

# ----------------------------------------
# ğŸ“¤ DAGãƒˆãƒªã‚¬ãƒ¼ï¼ˆGitHub Pushï¼‰
# ----------------------------------------

class DAGTriggerResponse(BaseModel):
    detail: str
    dag_run_id: str | None = None
    response_body: str | None = None

@router.post("/push/trigger", response_model=DAGTriggerResponse)
async def trigger_push_dag(strategy_name: str = Form(...)):
    """
    AirflowçµŒç”±ã§GitHubã«Pushã™ã‚‹DAGã‚’ãƒˆãƒªã‚¬ãƒ¼ï¼ˆveritas_push_dagï¼‰
    """
    strategy_name = strategy_name.strip()
    if not strategy_name:
        raise HTTPException(status_code=400, detail="strategy_name ãŒç©ºã§ã™")

    dag_run_id = f"veritas_push__{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    airflow_url = os.getenv("AIRFLOW_BASE_URL", "http://airflow-webserver:8080")
    dag_trigger_url = f"{airflow_url}/api/v1/dags/veritas_push_dag/dagRuns"

    payload = {
        "dag_run_id": dag_run_id,
        "conf": {
            "strategy_name": strategy_name
        }
    }

    try:
        response = requests.post(
            dag_trigger_url,
            auth=(os.getenv("AIRFLOW_USERNAME", "airflow"),
                  os.getenv("AIRFLOW_PASSWORD", "airflow")),
            json=payload,
            timeout=10
        )

        if response.status_code in (200, 201):
            return DAGTriggerResponse(
                detail=f"âœ… DAGãƒˆãƒªã‚¬ãƒ¼æˆåŠŸ (Run ID: {dag_run_id})",
                dag_run_id=dag_run_id
            )

        return DAGTriggerResponse(
            detail=f"âŒ Airflowã‚¨ãƒ©ãƒ¼å¿œç­” (HTTP {response.status_code})",
            response_body=response.text
        )

    except requests.RequestException as e:
        return DAGTriggerResponse(
            detail=f"ğŸš¨ Airflowé€šä¿¡å¤±æ•—: {str(e)}"
        )

# ----------------------------------------
# ğŸ“‹ Pushå±¥æ­´è¡¨ç¤ºï¼ˆGET /push/historyï¼‰
# ----------------------------------------

PAGE_SIZE = 50

@router.get("/push/history", response_class=HTMLResponse)
def view_push_history(
    request: Request,
    strategy: str = Query(default="", description="æˆ¦ç•¥å"),
    tag: str = Query(default="", description="ã‚¿ã‚°"),
    start_date: str = Query(default="", description="é–‹å§‹æ—¥"),
    end_date: str = Query(default="", description="çµ‚äº†æ—¥"),
    keyword: str = Query(default="", description="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ¤œç´¢"),
    sort: str = Query(default="desc", description="ä¸¦ã³é †"),
    page: int = Query(default=1, ge=1)
):
    logs = []

    if not PUSH_LOG_DIR.exists():
        PUSH_LOG_DIR.mkdir(parents=True)

    for file in sorted(PUSH_LOG_DIR.glob("*.json")):
        with open(file, "r", encoding="utf-8") as f:
            log = json.load(f)

            if strategy and strategy not in log.get("strategy", ""):
                continue
            if tag and tag != log.get("tag", ""):
                continue
            if keyword and keyword.lower() not in log.get("message", "").lower():
                continue

            log_date = log.get("timestamp", "")[:10]
            if start_date and log_date < start_date:
                continue
            if end_date and log_date > end_date:
                continue

            logs.append(log)

    logs.sort(
        key=lambda x: x.get("timestamp", ""),
        reverse=(sort != "asc")
    )

    tag_list = sorted({log.get("tag") for log in logs if log.get("tag")})

    total_count = len(logs)
    total_pages = max((total_count + PAGE_SIZE - 1) // PAGE_SIZE, 1)
    page = min(page, total_pages)
    start = (page - 1) * PAGE_SIZE
    end = start + PAGE_SIZE
    paged_logs = logs[start:end]

    return templates.TemplateResponse("push_history.html", {
        "request": request,
        "logs": paged_logs,
        "tag_list": tag_list,
        "filters": {
            "strategy": strategy,
            "tag": tag,
            "start_date": start_date,
            "end_date": end_date,
            "keyword": keyword,
            "sort": sort,
        },
        "total_count": total_count,
        "total_pages": total_pages,
        "current_page": page,
        "page_size": PAGE_SIZE,
    })

# ----------------------------------------
# ğŸ“¤ CSVå‡ºåŠ›ï¼ˆGET /push/exportï¼‰
# ----------------------------------------

@router.get("/push/export")
def export_push_history_csv(
    strategy: str = Query(default=""),
    tag: str = Query(default=""),
    start_date: str = Query(default=""),
    end_date: str = Query(default=""),
    keyword: str = Query(default="")
):
    logs = []

    for file in sorted(PUSH_LOG_DIR.glob("*.json")):
        with open(file, "r", encoding="utf-8") as f:
            log = json.load(f)

            if strategy and strategy not in log.get("strategy", ""):
                continue
            if tag and tag != log.get("tag", ""):
                continue
            if keyword and keyword.lower() not in log.get("message", "").lower():
                continue

            log_date = log.get("timestamp", "")[:10]
            if start_date and log_date < start_date:
                continue
            if end_date and log_date > end_date:
                continue

            logs.append(log)

    output = io.StringIO()
    writer = csv.DictWriter(output, fieldnames=["timestamp", "strategy", "tag", "message", "signature"])
    writer.writeheader()

    for log in logs:
        writer.writerow({
            "timestamp": log.get("timestamp", ""),
            "strategy": log.get("strategy", ""),
            "tag": log.get("tag", ""),
            "message": log.get("message", ""),
            "signature": log.get("signature", "")
        })

    output.seek(0)
    filename = f"push_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    return StreamingResponse(output, media_type="text/csv", headers={
        "Content-Disposition": f"attachment; filename={filename}"
    })

# ----------------------------------------
# ğŸ” è©³ç´°è¡¨ç¤ºï¼ˆGET /push/detailï¼‰
# ----------------------------------------

@router.get("/push/detail", response_class=HTMLResponse)
def push_history_detail(request: Request, timestamp: str):
    log_path = PUSH_LOG_DIR / f"{timestamp}.json"
    if not log_path.exists():
        raise HTTPException(status_code=404, detail="Log not found")

    with open(log_path, "r", encoding="utf-8") as f:
        log = json.load(f)

    return templates.TemplateResponse("push_history_detail.html", {
        "request": request,
        "log": log
    })
