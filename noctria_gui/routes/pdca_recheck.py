# noctria_gui/routes/pdca_recheck.py
# -*- coding: utf-8 -*-
"""
ğŸ” PDCA Recheck Routes (single & bulk) â€” v2.0

æä¾›ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ:
- POST /pdca/recheck        : å˜ä¸€æˆ¦ç•¥ã®å†è©•ä¾¡ãƒˆãƒªã‚¬ï¼ˆAirflow REST via airflow_clientï¼‰
- POST /pdca/recheck_all    : æœŸé–“/ãƒ•ã‚£ãƒ«ã‚¿ã§æŠ½å‡ºã—ãŸè¤‡æ•°æˆ¦ç•¥ã‚’ä¸€æ‹¬ãƒˆãƒªã‚¬

ç‰¹å¾´:
- Airflowé€£æºã¯ src/core/airflow_client.make_airflow_client() ã‚’åˆ©ç”¨ï¼ˆRESTæ¨å¥¨ï¼‰
- è¦³æ¸¬ãƒ­ã‚° (obs_infer_calls) ã¸ã®è¨˜éŒ²ã¯ best-effortï¼ˆæœªé…å‚™ã§ã‚‚å‡¦ç†ç¶™ç¶šï¼‰
- decision ledger (src/core/decision_registry.py) ãŒã‚ã‚Œã° accepted/started/completed/failed ã‚’è¨˜éŒ²
- æˆ¦ç•¥ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªã¯ .py/.json ä¸¡å¯¾å¿œã€veritas_generated/ ãŠã‚ˆã³ strategies/ ã‚’æ¢ç´¢
"""

from __future__ import annotations

import json
import os
import subprocess
import uuid
import urllib.parse
from datetime import datetime, timezone
from pathlib import Path
from typing import Optional, Dict, Any, List, Tuple

from fastapi import APIRouter, Body, Form, Query, Request, HTTPException
from fastapi.responses import JSONResponse, RedirectResponse
from fastapi.templating import Jinja2Templates

# ------------------------------------------------------------
# ãƒ‘ã‚¹/è¨­å®š
# ------------------------------------------------------------
_THIS = Path(__file__).resolve()
PROJECT_ROOT = _THIS.parents[2]  # <repo_root>

# path_config ãŒç„¡ã„ç’°å¢ƒã§ã‚‚è½ã¡ãªã„ã‚ˆã†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
try:
    from src.core.path_config import (
        STRATEGIES_DIR,
        NOCTRIA_GUI_TEMPLATES_DIR,
        PDCA_LOG_DIR as _PDCA_LOG_DIR_SETTING,
    )  # type: ignore
except Exception:  # pragma: no cover
    STRATEGIES_DIR = PROJECT_ROOT / "src" / "strategies"
    NOCTRIA_GUI_TEMPLATES_DIR = PROJECT_ROOT / "noctria_gui" / "templates"
    _PDCA_LOG_DIR_SETTING = None

PDCA_DIR = Path(_PDCA_LOG_DIR_SETTING) if _PDCA_LOG_DIR_SETTING else (PROJECT_ROOT / "data" / "pdca_logs" / "veritas_orders")
PDCA_DIR.mkdir(parents=True, exist_ok=True)

router = APIRouter(prefix="/pdca", tags=["PDCA"])
templates = Jinja2Templates(directory=str(NOCTRIA_GUI_TEMPLATES_DIR))

DEFAULT_SINGLE_RECHECK_DAG = os.getenv("AIRFLOW_DAG_RECHECK_SINGLE", "veritas_eval_single_dag")
BULK_RECHECK_DAG = os.getenv("AIRFLOW_DAG_RECHECK_BULK", "veritas_recheck_dag")
SCHEMA_VERSION = "2025-08-01"

# Airflow REST ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
from src.core.airflow_client import make_airflow_client  # type: ignore

# è¦³æ¸¬ãƒ­ã‚°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ï¼‰
try:
    from src.plan_data.observability import ensure_tables, log_infer_call  # type: ignore
except Exception:  # pragma: no cover
    ensure_tables = None
    log_infer_call = None  # type: ignore

# decision ledgerï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ï¼‰
try:
    from src.core.decision_registry import create_decision, append_event  # type: ignore
except Exception:  # pragma: no cover
    create_decision = None  # type: ignore
    append_event = None  # type: ignore


# ------------------------------------------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ------------------------------------------------------------
def _now_utc_iso() -> str:
    return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00", "Z")


def _obs_safe_log(trace_id: str, ai_name: str, params: Dict[str, Any], metrics: Dict[str, Any], status: str, note: str) -> None:
    if ensure_tables and log_infer_call:
        try:
            ensure_tables()
            now_iso = _now_utc_iso()
            log_infer_call(
                trace_id=trace_id,
                ai_name=ai_name,
                started_at=now_iso,
                ended_at=now_iso,
                params_json=params,
                metrics_json=metrics,
                status=status,
                note=note,
            )
        except Exception:
            pass


def _policy_snapshot() -> Dict[str, Any]:
    try:
        from src.core.policy_engine import get_snapshot  # type: ignore
        return dict(get_snapshot())
    except Exception:
        return {}


def _ledger_issue(kind: str, issued_by: str, intent: Dict[str, Any]) -> Optional[str]:
    if not create_decision:
        return None
    try:
        d = create_decision(kind, issued_by=issued_by, intent=intent, policy_snapshot=_policy_snapshot())
        return d.decision_id
    except Exception:
        return None


def _ledger_event(decision_id: Optional[str], phase: str, payload: Dict[str, Any]) -> None:
    if not decision_id or not append_event:
        return
    try:
        append_event(decision_id, phase, payload)
    except Exception:
        pass


def _strategy_candidates(name: str) -> List[Path]:
    """
    æˆ¦ç•¥ãƒ•ã‚¡ã‚¤ãƒ«ã®å€™è£œï¼ˆå­˜åœ¨ãƒã‚§ãƒƒã‚¯ç”¨ï¼‰
    - veritas_generated/{name}.py / .json
    - strategies/{name}.py / .json
    """
    vg = STRATEGIES_DIR / "veritas_generated"
    return [
        vg / f"{name}.py",
        vg / f"{name}.json",
        STRATEGIES_DIR / f"{name}.py",
        STRATEGIES_DIR / f"{name}.json",
    ]


def _strategy_exists(name: str) -> bool:
    return any(p.exists() for p in _strategy_candidates(name))


def _parse_ymd(s: Optional[str]) -> Optional[datetime]:
    if not s:
        return None
    try:
        y, m, d = s.split("-")
        return datetime(int(y), int(m), int(d))
    except Exception:
        return None


def _read_candidate_strategies(
    date_from: Optional[str],
    date_to: Optional[str],
    max_files: int = 120,
    max_targets: int = 50,
) -> List[str]:
    """
    data/pdca_logs/veritas_orders/rechecks_*.csv ã‚’æ–°ã—ã„é †ã«èµ°æŸ»ã€æœŸé–“å†…ã«è©•ä¾¡ã•ã‚ŒãŸ strategy ã‚’åé›†ã€‚
    pandas ä¸è¦ãƒ»é‡è¤‡é™¤å»ãƒ»æœ€å¤§ä»¶æ•°åˆ¶é™ã‚ã‚Šã€‚
    """
    df = _parse_ymd(date_from)
    dt = _parse_ymd(date_to)

    files = sorted(PDCA_DIR.glob("rechecks_*.csv"), key=lambda p: p.stat().st_mtime, reverse=True)[:max_files]
    seen = set()
    out: List[str] = []

    for fp in files:
        try:
            with fp.open("r", encoding="utf-8") as f:
                header = None
                for line in f:
                    line = line.rstrip("\n")
                    if not line:
                        continue
                    cols = line.split(",")
                    if header is None:
                        header = [c.strip() for c in cols]
                        continue
                    row = {header[i]: (cols[i] if i < len(header) else "") for i in range(len(header))}
                    strategy = row.get("strategy", "").strip()
                    if not strategy or strategy in seen:
                        continue

                    ok = True
                    if df or dt:
                        ts = row.get("evaluated_at", "")
                        try:
                            d = datetime.fromisoformat(ts.replace("Z", "+00:00")).date() if ts else None
                            if d:
                                if df and d < df.date():
                                    ok = False
                                if dt and d > dt.date():
                                    ok = False
                        except Exception:
                            pass
                    if not ok:
                        continue

                    seen.add(strategy)
                    out.append(strategy)
                    if len(out) >= max_targets:
                        break
        except Exception:
            continue
        if len(out) >= max_targets:
            break

    return out


# ------------------------------------------------------------
# Airflow ãƒˆãƒªã‚¬ï¼ˆCLIãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚ç”¨æ„: ç¾çŠ¶æœªä½¿ç”¨ï¼‰
# ------------------------------------------------------------
def _airflow_trigger_via_cli(dag_id: str, conf: Dict[str, Any]) -> Tuple[bool, str, Optional[str]]:
    try:
        run_id = f"manual__noctria__{conf.get('decision_id','unknown')}"
        cmd = ["airflow", "dags", "trigger", dag_id, "--run-id", run_id, "--conf", json.dumps(conf, ensure_ascii=False)]
        cp = subprocess.run(cmd, capture_output=True, text=True, timeout=15)
        ok = cp.returncode == 0
        msg = cp.stdout.strip() if ok else (cp.stderr.strip() or cp.stdout.strip())
        return ok, f"CLI: {msg}", run_id if ok else None
    except Exception as e:
        return False, f"CLI error: {e}", None


# ------------------------------------------------------------
# Routes
# ------------------------------------------------------------
@router.post("/recheck")
async def recheck_strategy(strategy_name: str = Form(...)):
    """
    å˜ä¸€æˆ¦ç•¥ã®å†è©•ä¾¡ã‚’ Airflowï¼ˆRESTï¼‰ã§ãƒˆãƒªã‚¬ã€‚
    æˆåŠŸæ™‚ã¯ /statistics/detail?mode=strategy&key={strategy_name} ã¸ 303 Redirectã€‚
    """
    if not _strategy_exists(strategy_name):
        return JSONResponse(status_code=404, content={"detail": f"æˆ¦ç•¥ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {strategy_name}", "strategy_name": strategy_name})

    dag_id = DEFAULT_SINGLE_RECHECK_DAG.strip()
    trace_id = str(uuid.uuid4())
    decision_id: Optional[str] = _ledger_issue(
        kind="recheck",
        issued_by="ui",
        intent={"strategy": strategy_name, "reason": "single_recheck"},
    )
    _ledger_event(decision_id, "accepted", {"endpoint": "/pdca/recheck"})

    conf: Dict[str, Any] = {
        "schema_version": SCHEMA_VERSION,
        "trigger_source": "GUI",
        "trace_id": trace_id,
        "requested_at": _now_utc_iso(),
        "mode": "strategy",
        "strategy_name": strategy_name,
        "reason": "single_recheck",
        "dry_run": False,
        "decision_id": decision_id or "NO_DECISION_ID",
        "caller": "ui",
    }
    _ledger_event(decision_id, "started", {"dag_id": dag_id, "conf": conf})

    try:
        client = make_airflow_client()
        res = client.trigger_dag_run(
            dag_id=dag_id,
            conf=conf,
            note=f"Single Recheck from GUI (strategy={strategy_name}, trace_id={trace_id})",
        )
        dag_run_id = res.get("dag_run_id")

        _obs_safe_log(
            trace_id=trace_id,
            ai_name="PDCA_SingleRecheckTrigger",
            params={"dag_id": dag_id, **conf},
            metrics={"dag_run_id": dag_run_id or "", "response": res},
            status="success",
            note="GUI trigger single recheck",
        )
        _ledger_event(decision_id, "completed", {"dag_run_id": dag_run_id, "response": res})

    except Exception as e:
        _obs_safe_log(
            trace_id=trace_id,
            ai_name="PDCA_SingleRecheckTrigger",
            params={"dag_id": dag_id, **conf},
            metrics={"error": str(e)},
            status="failed",
            note="GUI trigger single recheck failed",
        )
        _ledger_event(decision_id, "failed", {"error": str(e)})
        return JSONResponse(status_code=500, content={"detail": f"Airflow DAGãƒˆãƒªã‚¬ãƒ¼å¤±æ•—: {str(e)}", "strategy_name": strategy_name})

    # Redirect to statistics detail
    query = urllib.parse.urlencode({"mode": "strategy", "key": strategy_name, "trace_id": trace_id, "decision_id": decision_id or ""})
    return RedirectResponse(url=f"/statistics/detail?{query}", status_code=303)


@router.post("/recheck_all")
async def recheck_all(
    reason: str = Query("", description="ä¸€æ‹¬å†è©•ä¾¡ã®ç†ç”±ï¼ˆä»»æ„ï¼‰"),
    filter_date_from: Optional[str] = Query(None, description="YYYY-MM-DD"),
    filter_date_to: Optional[str] = Query(None, description="YYYY-MM-DD"),
    max_targets: int = Query(30, ge=1, le=200, description="æœ€å¤§ãƒˆãƒªã‚¬ä»¶æ•°ï¼ˆå®‰å…¨ä¸Šé™ã‚ã‚Šï¼‰"),
) -> JSONResponse:
    """
    æœŸé–“ã§æŠ½å‡ºã•ã‚ŒãŸè¤‡æ•°æˆ¦ç•¥ã‚’å¯¾è±¡ã« Airflow `veritas_recheck_dag` ã‚’é †æ¬¡ãƒˆãƒªã‚¬ã€‚
    - decision_id ã¯1ä»¶ãšã¤è‡ªå‹•ç™ºè¡Œ
    - å¤±æ•—ã—ã¦ã‚‚å…¨ä½“ã¯ç¶šè¡Œ
    """
    strategies = _read_candidate_strategies(filter_date_from, filter_date_to, max_targets=max_targets)
    if not strategies:
        return JSONResponse({"ok": True, "message": "å¯¾è±¡æˆ¦ç•¥ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", "triggered": 0, "results": []})

    results: List[Dict[str, Any]] = []
    dag_id = BULK_RECHECK_DAG.strip()

    for s in strategies:
        decision_id = _ledger_issue(
            kind="recheck",
            issued_by="ui",
            intent={"strategy": s, "reason": reason, "filter": {"from": filter_date_from, "to": filter_date_to}},
        )
        _ledger_event(decision_id, "accepted", {"endpoint": "/pdca/recheck_all"})

        trace_id = str(uuid.uuid4())
        conf = {
            "schema_version": SCHEMA_VERSION,
            "trigger_source": "GUI",
            "trace_id": trace_id,
            "requested_at": _now_utc_iso(),
            "mode": "strategy",
            "strategy_name": s,
            "reason": reason or "",
            "dry_run": False,
            "decision_id": decision_id or "NO_DECISION_ID",
            "caller": "ui",
        }
        _ledger_event(decision_id, "started", {"dag_id": dag_id, "conf": conf})

        try:
            client = make_airflow_client()
            res = client.trigger_dag_run(
                dag_id=dag_id,
                conf=conf,
                note=f"Bulk Recheck from GUI (strategy={s}, trace_id={trace_id})",
            )
            dag_run_id = res.get("dag_run_id")

            _obs_safe_log(
                trace_id=trace_id,
                ai_name="PDCA_BulkRecheckTrigger",
                params={"dag_id": dag_id, **conf},
                metrics={"dag_run_id": dag_run_id or "", "response": res},
                status="success",
                note="GUI trigger bulk recheck",
            )
            _ledger_event(decision_id, "completed", {"dag_run_id": dag_run_id, "response": res})

            results.append({"strategy": s, "ok": True, "message": "Triggered", "dag_run_id": dag_run_id, "decision_id": decision_id})
        except Exception as e:
            _obs_safe_log(
                trace_id=trace_id,
                ai_name="PDCA_BulkRecheckTrigger",
                params={"dag_id": dag_id, **conf},
                metrics={"error": str(e)},
                status="failed",
                note="GUI trigger bulk recheck failed",
            )
            _ledger_event(decision_id, "failed", {"error": str(e)})

            results.append({"strategy": s, "ok": False, "message": f"Trigger failed: {e}", "dag_run_id": None, "decision_id": decision_id})

    succeeded = sum(1 for r in results if r["ok"])
    failed = len(results) - succeeded

    return JSONResponse(
        {
            "ok": failed == 0,
            "message": f"ä¸€æ‹¬å†è©•ä¾¡ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼ˆæˆåŠŸ {succeeded} / å¤±æ•— {failed} / å¯¾è±¡ {len(results)}ï¼‰ã€‚",
            "triggered": len(results),
            "succeeded": succeeded,
            "failed": failed,
            "results": results,
            "filters": {"from": filter_date_from, "to": filter_date_to},
        }
    )


# å‚è€ƒ: å±¥æ­´ãƒšãƒ¼ã‚¸ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãŒç„¡ã„ç’°å¢ƒã§ã‚‚èµ·å‹•ã‚’æ­¢ã‚ãªã„ï¼‰
@router.get("/history", include_in_schema=False)
async def pdca_history(request: Request):
    tpl = NOCTRIA_GUI_TEMPLATES_DIR / "pdca" / "history.html"
    if not tpl.exists():
        return JSONResponse({"ok": True, "message": "history.html not found (placeholder)."})
    return templates.TemplateResponse("pdca/history.html", {"request": request})
