#!/usr/bin/env python3
# coding: utf-8
"""
Noctria Kingdom - Optunaæœ€é©åŒ– å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆAirflow/CLIä¸¡å¯¾å¿œãƒ»é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆç‰ˆï¼‰

ç‰¹å¾´:
- 0.0 å›ºå®šã‚¹ã‚³ã‚¢å¯¾ç­–ï¼ˆè©•ä¾¡ãƒ©ãƒƒãƒ‘ã€NaN/Inf é˜²å¾¡ã€æ—©æœŸçµ‚äº†ä¾‹å¤–ã®å¥å…¨åŒ–ï¼‰
- ã‚µãƒ³ãƒ—ãƒ©ãƒ¼/ãƒ—ãƒ«ãƒ¼ãƒŠãƒ¼é©æ­£åŒ–ï¼ˆTPESampler + MedianPruner æ—¢å®šï¼‰
- ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¤‡æ•°å›ã®å®‰å®šè©•ä¾¡ + ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
- åˆ†æ•£å®Ÿè¡Œï¼ˆRDBã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ï¼‰: PostgreSQLæƒ³å®š
- é‡ã„ä¾å­˜ã¯é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§DagBagã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå›é¿
- å®Œå…¨è‡ªå·±å®Œçµ: CLIå¼•æ•° & ç’°å¢ƒå¤‰æ•°ä¸¡å¯¾å¿œ
"""

from __future__ import annotations
import os
import sys
import math
import json
import time
import random
import argparse
from dataclasses import dataclass
from typing import Any, Dict, Optional, Tuple

# --- ã§ãã‚‹é™ã‚Šè»½é‡ãªæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã¿ã‚’ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã§ import ---
from datetime import datetime
from pathlib import Path

# --- æ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‘ã‚¹è§£æ±ºï¼ˆsrc/çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆçµ±ä¸€ï¼‰ ---
PROJECT_ROOT = Path(__file__).resolve().parents[2]  # .../noctria_kingdom/src/metaai/.. -> /noctria_kingdom
SRC_ROOT = PROJECT_ROOT / "src"
if str(SRC_ROOT) not in sys.path:
    sys.path.insert(0, str(SRC_ROOT))

# ãƒ­ã‚°å‡ºåŠ›
def _log(msg: str) -> None:
    ts = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{ts} UTC] {msg}", flush=True)

# ---- è¨­å®šãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ ----
@dataclass
class OptunaConfig:
    study_name: str
    storage_url: Optional[str]
    n_trials: int
    timeout_sec: Optional[int]
    n_startup_trials: int
    n_eval_episodes: int
    max_train_steps: int
    sampler: str
    pruner: str
    seed: int
    tb_logdir: Optional[str]
    env_id: str
    reward_clip: Optional[float]
    minimize: bool
    allow_prune_after: int
    # åˆ†æ•£ãƒ¯ãƒ¼ã‚«ãƒ¼IDENT
    worker_tag: str

def build_config(args: argparse.Namespace) -> OptunaConfig:
    # envå„ªå…ˆâ†’å¼•æ•°ã®é †ã§è§£æ±º
    def env_or_arg(key: str, default: Any):
        return os.getenv(key, getattr(args, key, default)) or default

    storage = env_or_arg("OPTUNA_STORAGE", args.storage_url)
    if isinstance(storage, str) and storage.strip() == "":
        storage = None

    return OptunaConfig(
        study_name=env_or_arg("STUDY_NAME", args.study_name),
        storage_url=storage,
        n_trials=int(env_or_arg("N_TRIALS", args.n_trials)),
        timeout_sec=int(env_or_arg("TIMEOUT_SEC", args.timeout_sec)) if env_or_arg("TIMEOUT_SEC", args.timeout_sec) else None,
        n_startup_trials=int(env_or_arg("N_STARTUP_TRIALS", args.n_startup_trials)),
        n_eval_episodes=int(env_or_arg("N_EVAL_EPISODES", args.n_eval_episodes)),
        max_train_steps=int(env_or_arg("MAX_TRAIN_STEPS", args.max_train_steps)),
        sampler=str(env_or_arg("SAMPLER", args.sampler)).lower(),
        pruner=str(env_or_arg("PRUNER", args.pruner)).lower(),
        seed=int(env_or_arg("SEED", args.seed)),
        tb_logdir=env_or_arg("TB_LOGDIR", args.tb_logdir),
        env_id=str(env_or_arg("ENV_ID", args.env_id)),
        reward_clip=float(env_or_arg("REWARD_CLIP", args.reward_clip)) if env_or_arg("REWARD_CLIP", args.reward_clip) else None,
        minimize=bool(str(env_or_arg("MINIMIZE", args.minimize)).lower() in ("1","true","yes")),
        allow_prune_after=int(env_or_arg("ALLOW_PRUNE_AFTER", args.allow_prune_after)),
        worker_tag=str(env_or_arg("WORKER_TAG", args.worker_tag)),
    )

# --- é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆé‡ã„ä¾å­˜ï¼‰ ---
def _lazy_imports():
    import numpy as np  # noqa
    import optuna  # noqa
    from optuna import Trial  # noqa
    from optuna.samplers import TPESampler, RandomSampler  # noqa
    from optuna.pruners import MedianPruner, SuccessiveHalvingPruner, NopPruner  # noqa

    # Stable-Baselines3 ã¯é…å»¶
    try:
        from stable_baselines3 import PPO
        from stable_baselines3.common.vec_env import DummyVecEnv
        from stable_baselines3.common.evaluation import evaluate_policy
    except Exception as e:
        _log(f"âš ï¸ SB3 importã«å¤±æ•—: {e}. å¿…è¦ãªã‚‰ 'pip install stable-baselines3' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        raise

    # Gymnasiumã‚„ç’°å¢ƒ
    try:
        import gymnasium as gym
    except Exception:
        import gym  # æ—§gym fallback
        gym.logger.set_level(40)

    return {
        "np": __import__("numpy"),
        "optuna": __import__("optuna"),
        "TPESampler": __import__("optuna.samplers", fromlist=["TPESampler"]).TPESampler,
        "RandomSampler": __import__("optuna.samplers", fromlist=["RandomSampler"]).RandomSampler,
        "MedianPruner": __import__("optuna.pruners", fromlist=["MedianPruner"]).MedianPruner,
        "SuccessiveHalvingPruner": __import__("optuna.pruners", fromlist=["SuccessiveHalvingPruner"]).SuccessiveHalvingPruner,
        "NopPruner": __import__("optuna.pruners", fromlist=["NopPruner"]).NopPruner,
        "PPO": __import__("stable_baselines3", fromlist=["PPO"]).PPO,
        "DummyVecEnv": __import__("stable_baselines3.common.vec_env", fromlist=["DummyVecEnv"]).DummyVecEnv,
        "evaluate_policy": __import__("stable_baselines3.common.evaluation", fromlist=["evaluate_policy"]).evaluate_policy,
        "gym": __import__("gymnasium") if "gymnasium" in sys.modules else __import__("gym"),
    }

# --- ã‚µãƒ³ãƒ—ãƒ©ãƒ¼/ãƒ—ãƒ«ãƒ¼ãƒŠãƒ¼ã®é¸æŠ ---
def _make_sampler_pruner(cfg: OptunaConfig, optuna_mod) -> Tuple[Any, Any]:
    Samplers = {
        "tpe": __import__("optuna.samplers", fromlist=["TPESampler"]).TPESampler,
        "random": __import__("optuna.samplers", fromlist=["RandomSampler"]).RandomSampler,
    }
    Pruners = {
        "median": __import__("optuna.pruners", fromlist=["MedianPruner"]).MedianPruner,
        "sha": __import__("optuna.pruners", fromlist=["SuccessiveHalvingPruner"]).SuccessiveHalvingPruner,
        "none": __import__("optuna.pruners", fromlist=["NopPruner"]).NopPruner,
    }
    sampler_cls = Samplers.get(cfg.sampler, Samplers["tpe"])
    pruner_cls = Pruners.get(cfg.pruner, Pruners["median"])

    sampler = sampler_cls(seed=cfg.seed)
    if pruner_cls.__name__ == "MedianPruner":
        pruner = pruner_cls(n_startup_trials=cfg.n_startup_trials, n_warmup_steps=0)
    elif pruner_cls.__name__ == "SuccessiveHalvingPruner":
        pruner = pruner_cls(min_resource=cfg.allow_prune_after, reduction_factor=3)
    else:
        pruner = pruner_cls()
    return sampler, pruner

# --- è©•ä¾¡é–¢æ•° ---
def _safe_mean(xs):
    xs = [x for x in xs if x is not None and not math.isnan(x) and math.isfinite(x)]
    return float(sum(xs) / len(xs)) if xs else 0.0

def make_objective(cfg: OptunaConfig):
    mods = _lazy_imports()
    np = mods["np"]
    gym = mods["gym"]
    PPO = mods["PPO"]
    DummyVecEnv = mods["DummyVecEnv"]
    evaluate_policy = mods["evaluate_policy"]
    optuna_mod = mods["optuna"]

    # ä¹±æ•°å›ºå®š
    random.seed(cfg.seed)
    np.random.seed(cfg.seed)
    try:
        import torch
        torch.manual_seed(cfg.seed)
    except Exception:
        pass

    def objective(trial: "optuna.trial.Trial") -> float:
        # --- æ¢ç´¢ç©ºé–“ï¼ˆå¿…è¦ã«å¿œã˜ã¦èª¿æ•´ï¼‰ ---
        learning_rate = trial.suggest_float("learning_rate", 1e-5, 5e-3, log=True)
        n_steps = trial.suggest_int("n_steps", 128, 2048, step=128)
        gamma = trial.suggest_float("gamma", 0.90, 0.999, step=0.001)
        ent_coef = trial.suggest_float("ent_coef", 0.0, 0.02, step=0.0005)
        clip_range = trial.suggest_float("clip_range", 0.1, 0.4, step=0.02)
        gae_lambda = trial.suggest_float("gae_lambda", 0.8, 0.99, step=0.01)
        vf_coef = trial.suggest_float("vf_coef", 0.2, 1.0, step=0.05)
        batch_size = trial.suggest_categorical("batch_size", [64, 128, 256, 512])

        # --- ç’°å¢ƒæ§‹ç¯‰ï¼ˆVecEnvï¼‰ ---
        def _make_env():
            env = gym.make(cfg.env_id)
            try:
                env.reset(seed=cfg.seed)
            except Exception:
                pass
            return env
        env = DummyVecEnv([_make_env])

        # --- ãƒ¢ãƒ‡ãƒ« ---
        model = PPO(
            "MlpPolicy",
            env,
            learning_rate=learning_rate,
            n_steps=n_steps,
            batch_size=batch_size,
            gamma=gamma,
            ent_coef=ent_coef,
            clip_range=clip_range,
            gae_lambda=gae_lambda,
            vf_coef=vf_coef,
            verbose=0,
            seed=cfg.seed,
            tensorboard_log=cfg.tb_logdir,
        )

        # --- å­¦ç¿’ ---
        try:
            model.learn(total_timesteps=cfg.max_train_steps, progress_bar=False)
        except Exception as e:
            # æ—©æœŸçµ‚äº†ã‚„NaNã§è½ã¡ãŸå ´åˆã¯ãƒšãƒŠãƒ«ãƒ†ã‚£
            _log(f"âš ï¸ learnä¸­ã«ä¾‹å¤–: {e}")
            try:
                env.close()
            except Exception:
                pass
            # æ¥µç«¯ãªæ‚ªè©•ä¾¡ã‚’è¿”ã—ã¦ç¶™ç¶šï¼ˆ0å¼µã‚Šä»˜ãå›é¿ï¼‰
            return 1e9 if cfg.minimize else -1e9

        # --- è©•ä¾¡ï¼ˆè¤‡æ•°ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å¹³å‡ + ã‚¯ãƒªãƒƒãƒ—ï¼‰ ---
        rets = []
        for _ in range(cfg.n_eval_episodes):
            try:
                mean_r, _ = evaluate_policy(model, env, n_eval_episodes=1, deterministic=True, warn=False)
                if cfg.reward_clip:
                    mean_r = max(-cfg.reward_clip, min(cfg.reward_clip, mean_r))
                rets.append(float(mean_r))
            except Exception as e:
                _log(f"âš ï¸ evaluateä¸­ã«ä¾‹å¤–: {e}")
                rets.append(0.0)

        score = _safe_mean(rets)

        # --- 0.0å›ºå®šã®æ¤œçŸ¥ã¨å›é¿ï¼ˆå·®åˆ†ãƒ­ã‚°ï¼‰ ---
        if abs(score) < 1e-12:
            _log("âš ï¸ è©•ä¾¡ãŒ0.0ã«å¼µã‚Šä»˜ã„ã¦ã„ã¾ã™ã€‚ç’°å¢ƒ/å ±é…¬ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚trial params="
                 + json.dumps(trial.params, ensure_ascii=False))

        # --- é€”ä¸­çµŒéã‚’reportã—ã¦pruneå¯èƒ½ã« ---
        trial.report(score, step=cfg.max_train_steps)
        if trial.should_prune():
            # è¨±å®¹ã‚¹ãƒ†ãƒƒãƒ—å‰ã¯ç„¡è¦–ï¼ˆMedianPrunerã®éå‰°ç™ºç«æŠ‘åˆ¶ï¼‰
            if cfg.max_train_steps >= cfg.allow_prune_after:
                try:
                    env.close()
                except Exception:
                    pass
                raise optuna_mod.TrialPruned()

        try:
            env.close()
        except Exception:
            pass

        # Optunaã¯ã€Œæœ€å°åŒ–ã€ãŒæ—¢å®šã€‚maximizeæ™‚ã¯è² ã«ã—ã¦è¿”ã™ã‹ã€æ–¹å‘ã‚’è¨­å®šã™ã‚‹ï¼ˆå¾Œè€…ã‚’æ¡ç”¨ï¼‰
        return float(score)

    return objective

def run(cfg: OptunaConfig) -> Dict[str, Any]:
    mods = _lazy_imports()
    optuna_mod = mods["optuna"]

    # ã‚µãƒ³ãƒ—ãƒ©ãƒ¼/ãƒ—ãƒ«ãƒ¼ãƒŠãƒ¼
    sampler, pruner = _make_sampler_pruner(cfg, optuna_mod)

    # Studyä½œæˆï¼ˆæ–¹å‘ã‚’è¨­å®šï¼‰
    direction = "minimize" if cfg.minimize else "maximize"
    _log(f"ğŸ¯ Study: {cfg.study_name} ({direction}), storage={cfg.storage_url}, worker={cfg.worker_tag}")
    study = optuna_mod.create_study(
        study_name=cfg.study_name,
        storage=cfg.storage_url,
        direction=direction,
        sampler=sampler,
        pruner=pruner,
        load_if_exists=True,
    )

    objective = make_objective(cfg)

    # å®Ÿè¡Œ
    study.optimize(
        objective,
        n_trials=cfg.n_trials,
        timeout=cfg.timeout_sec,
        gc_after_trial=True,
        n_jobs=1,  # åˆ†æ•£ã¯ãƒ—ãƒ­ã‚»ã‚¹/ã‚³ãƒ³ãƒ†ãƒŠã‚’å¢—ã‚„ã™ï¼ˆRDBã§åŒæœŸï¼‰
        catch=(Exception,),  # è©•ä¾¡å´ã®ä¾‹å¤–ã‚’æ½°ã—ã¦é€²è¡Œ
    )

    best_value = study.best_value if study.best_trial else (math.inf if cfg.minimize else -math.inf)
    best_params = study.best_trial.params if study.best_trial else {}
    _log(f"âœ… æœ€é©åŒ–å®Œäº†: best_value={best_value}, best_params={best_params}")

    return {
        "study_name": cfg.study_name,
        "best_value": best_value,
        "best_params": best_params,
        "n_trials": len(study.trials),
        "datetime_utc": datetime.utcnow().isoformat(),
        "worker_tag": cfg.worker_tag,
    }

def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(description="Noctria - Optunaæœ€é©åŒ–å®Ÿè¡Œ")
    p.add_argument("--study_name", type=str, default="noctria_rl_ppo")
    p.add_argument("--storage_url", type=str, default=os.getenv("OPTUNA_STORAGE", ""))  # e.g. postgresql+psycopg2://airflow:airflow@noctria_postgres:5432/airflow
    p.add_argument("--n_trials", type=int, default=100)
    p.add_argument("--timeout_sec", type=int, default=None)
    p.add_argument("--n_startup_trials", type=int, default=10)
    p.add_argument("--n_eval_episodes", type=int, default=5)
    p.add_argument("--max_train_steps", type=int, default=100_000)
    p.add_argument("--sampler", type=str, default="tpe", choices=["tpe", "random"])
    p.add_argument("--pruner", type=str, default="median", choices=["median", "sha", "none"])
    p.add_argument("--seed", type=int, default=42)
    p.add_argument("--tb_logdir", type=str, default=None)
    p.add_argument("--env_id", type=str, default="CartPole-v1")  # å®Ÿãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ENVã«ç½®æ›ã™ã‚‹
    p.add_argument("--reward_clip", type=float, default=None)
    p.add_argument("--minimize", action="store_true", help="ç›®çš„é–¢æ•°ã‚’æœ€å°åŒ–ã™ã‚‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æœ€å¤§åŒ–ï¼‰")
    p.add_argument("--allow_prune_after", type=int, default=2_000)
    p.add_argument("--worker_tag", type=str, default=f"worker-{os.getenv('HOSTNAME','local')}")
    return p.parse_args()

def main():
    args = parse_args()
    cfg = build_config(args)
    result = run(cfg)
    print(json.dumps(result, ensure_ascii=False))

if __name__ == "__main__":
    main()
