#!/usr/bin/env python3
# coding: utf-8

"""
ğŸ”® Prometheus Oracle (æ¨™æº–feature_orderæº–æ‹ )
- Planå±¤ã§ç”Ÿæˆã—ãŸæ¨™æº–ç‰¹å¾´é‡DataFrameã‹ã‚‰æœªæ¥äºˆæ¸¬
- feature_order ã¯ Plan å±¤è¨­è¨ˆã§æ¨™æº–åŒ–ãƒ»é€£æº
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from datetime import datetime, timedelta
from typing import Optional, List
from pathlib import Path
import logging

from src.core.path_config import VERITAS_MODELS_DIR, ORACLE_FORECAST_JSON
from src.plan_data.standard_feature_schema import STANDARD_FEATURE_ORDER

logging.basicConfig(level=logging.INFO, format="%(asctime)s - [%(levelname)s] - %(message)s")


class PrometheusOracle:
    def __init__(
        self,
        model_path: Optional[Path] = None,
        feature_order: Optional[List[str]] = None,
    ):
        self.feature_order = feature_order or STANDARD_FEATURE_ORDER
        self.model_path = model_path or (VERITAS_MODELS_DIR / "prometheus_oracle.keras")
        self.model = self._load_or_build_model(input_dim=len(self.feature_order))

    # -------------------- Model I/O --------------------
    def _load_or_build_model(self, input_dim: int) -> tf.keras.Model:
        if self.model_path.exists():
            logging.info(f"ç¥è¨—ãƒ¢ãƒ‡ãƒ«èª­è¾¼: {self.model_path}")
            try:
                return tf.keras.models.load_model(self.model_path)
            except Exception as e:
                logging.error(f"ç¥è¨—ãƒ¢ãƒ‡ãƒ«èª­è¾¼å¤±æ•—: {e}")

        logging.info(f"æ–°è¦ç¥è¨—ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ (input_dim={input_dim})")
        inputs = tf.keras.Input(shape=(input_dim,), dtype=tf.float32, name="features")
        x = tf.keras.layers.Dense(64, activation="relu")(inputs)
        x = tf.keras.layers.Dense(32, activation="relu")(x)
        outputs = tf.keras.layers.Dense(1, name="yhat")(x)
        model = tf.keras.Model(inputs=inputs, outputs=outputs, name="prometheus_oracle")
        model.compile(optimizer="adam", loss="mse")
        return model

    def save_model(self):
        try:
            self.model_path.parent.mkdir(parents=True, exist_ok=True)
            self.model.save(self.model_path)
            logging.info(f"ç¥è¨—ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {self.model_path}")
        except Exception as e:
            logging.error(f"ç¥è¨—ãƒ¢ãƒ‡ãƒ«ä¿å­˜å¤±æ•—: {e}")

    # -------------------- Data prep --------------------
    def _align_and_clean(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        - feature_order ã«åˆã‚ã›ã¦åˆ—ã‚’ä¸¦ã¹ã‚‹/ä¸è¶³åˆ—ã¯ 0.0 ã§æ–°è¨­
        - æ•°å€¤åŒ–ï¼ˆéæ•°å€¤ã¯ NaNï¼‰
        - ffill/bfill ã§é€£ç¶šåŸ‹ã‚
        - æ®‹ã‚‹ NaN / inf / -inf ã¯ 0.0 ã«ç½®æ›
        """
        work = df.copy()

        # å¿…è¦åˆ—ã®ç¢ºä¿ï¼ˆä¸è¶³åˆ—ã¯ 0.0ï¼‰
        for col in self.feature_order:
            if col not in work.columns:
                work[col] = 0.0

        # æ•°å€¤åŒ–
        work[self.feature_order] = work[self.feature_order].apply(
            pd.to_numeric, errors="coerce"
        )

        # é€£ç¶šåŸ‹ã‚ï¼ˆå‰â†’å¾Œï¼‰
        work[self.feature_order] = work[self.feature_order].ffill().bfill()

        # æ®‹ NaN/inf ã‚’ 0.0
        work[self.feature_order] = work[self.feature_order].replace(
            [np.inf, -np.inf], np.nan
        ).fillna(0.0)

        # å‹ã¯ float32 ã«å¯„ã›ã‚‹ï¼ˆTF ã¨ç›¸æ€§è‰¯ï¼‰
        work[self.feature_order] = work[self.feature_order].astype(np.float32)

        # ãƒ‡ãƒãƒƒã‚°: NaN ãƒã‚§ãƒƒã‚¯
        nan_counts = work[self.feature_order].isna().sum().sum()
        if nan_counts:
            logging.warning(f"å‰å‡¦ç†å¾Œã«ã‚‚ NaN ãŒ {nan_counts} å€‹æ®‹å­˜ â†’ 0.0 ç½®æ›æ¸ˆã¿")

        return work[self.feature_order]

    # -------------------- Train / Predict --------------------
    def train(
        self,
        features_df: pd.DataFrame,
        target_col: str,
        epochs: int = 10,
        batch_size: int = 32,
    ):
        X = self._align_and_clean(features_df).values
        y = pd.to_numeric(features_df[target_col], errors="coerce").ffill().bfill()
        y = y.replace([np.inf, -np.inf], np.nan).fillna(0.0).astype(np.float32).values

        self.model = self._load_or_build_model(input_dim=len(self.feature_order))
        self.model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=1)
        self.save_model()

    def predict_future(
        self,
        features_df: pd.DataFrame,
        n_days: int = 14,
        decision_id: Optional[str] = None,
        caller: Optional[str] = "king_noctria",
        reason: Optional[str] = None,
    ) -> pd.DataFrame:
        # å®‰å…¨ãªå‰å‡¦ç†
        clean = self._align_and_clean(features_df)

        # è¡Œæ•°ãŒè¶³ã‚Šãªã„å ´åˆã¯ã‚ã‚‹åˆ†ã ã‘
        n = min(n_days, len(clean))
        if n == 0:
            # ä½•ã‚‚ãªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼ 1 è¡Œè¿”ã™
            logging.warning("predict_future: å…¥åŠ›è¡ŒãŒ 0 ã®ãŸã‚ãƒ€ãƒŸãƒ¼è¡Œã‚’è¿”ã—ã¾ã™ã€‚")
            dates = [str(datetime.today())[:10]]
            return pd.DataFrame(
                {
                    "date": dates,
                    "forecast": [np.nan],
                    "lower": [np.nan],
                    "upper": [np.nan],
                    "decision_id": [decision_id],
                    "caller": [caller],
                    "reason": [reason],
                }
            )

        df_input = clean.tail(n)
        X_input = df_input.values

        # æ¨è«–
        y_pred = self.model.predict(X_input, verbose=0).astype(np.float32).flatten()

        # ä¿¡é ¼å¹…ï¼ˆå˜ç´”ãªåˆ†æ•£ãƒ™ãƒ¼ã‚¹ï¼‰
        if len(y_pred) > 1 and not np.allclose(np.std(y_pred), 0.0):
            confidence_margin = float(np.std(y_pred) * 1.5)
        else:
            confidence_margin = 2.0

        y_lower = y_pred - confidence_margin
        y_upper = y_pred + confidence_margin

        # æ—¥ä»˜åˆ—ï¼šã‚ã‚Œã° 'date' ã‚’å„ªå…ˆã€ç„¡ã‘ã‚Œã°ä»Šæ—¥ã‹ã‚‰ã®é€£ç•ª
        if "date" in features_df.columns:
            dates = pd.to_datetime(features_df["date"]).dt.strftime("%Y-%m-%d").tail(n).tolist()
        elif "Date" in features_df.columns:
            dates = pd.to_datetime(features_df["Date"]).dt.strftime("%Y-%m-%d").tail(n).tolist()
        else:
            dates = [(datetime.today() + timedelta(days=i)).strftime("%Y-%m-%d") for i in range(n)]

        out = pd.DataFrame(
            {
                "date": dates,
                "forecast": np.round(y_pred, 4),
                "lower": np.round(y_lower, 4),
                "upper": np.round(y_upper, 4),
                "decision_id": decision_id,
                "caller": caller,
                "reason": reason,
            }
        )
        return out

    def write_forecast_json(
        self,
        features_df: pd.DataFrame,
        n_days: int = 14,
        decision_id: Optional[str] = None,
        caller: Optional[str] = "king_noctria",
        reason: Optional[str] = None,
    ):
        df = self.predict_future(features_df, n_days, decision_id, caller, reason)
        try:
            ORACLE_FORECAST_JSON.parent.mkdir(parents=True, exist_ok=True)
            df.to_json(ORACLE_FORECAST_JSON, orient="records", force_ascii=False, indent=4)
            logging.info(f"äºˆæ¸¬çµæœä¿å­˜: {ORACLE_FORECAST_JSON}")
        except Exception as e:
            logging.error(f"äºˆæ¸¬JSONä¿å­˜å¤±æ•—: {e}")


# === ãƒ†ã‚¹ãƒˆä¾‹ ===
if __name__ == "__main__":
    logging.info("--- Prometheus Oracle feature_orderãƒ†ã‚¹ãƒˆ ---")
    # ç–‘ä¼¼ãƒ‡ãƒ¼ã‚¿ï¼ˆNaN ã‚’æ··ãœã¦å …ç‰¢æ€§ãƒã‚§ãƒƒã‚¯ï¼‰
    rng = np.random.RandomState(0)
    test_df = pd.DataFrame(rng.rand(30, len(STANDARD_FEATURE_ORDER)), columns=STANDARD_FEATURE_ORDER)
    test_df.loc[5:7, STANDARD_FEATURE_ORDER[0]] = np.nan
    test_df["target"] = test_df[STANDARD_FEATURE_ORDER[0]].shift(-1)

    oracle = PrometheusOracle(feature_order=STANDARD_FEATURE_ORDER)
    oracle.train(test_df, target_col="target", epochs=2, batch_size=8)
    forecast_df = oracle.predict_future(test_df, n_days=5, decision_id="KC-TEST", caller="test", reason="unit_test")
    print(forecast_df.tail(5))
    oracle.write_forecast_json(test_df, n_days=5, decision_id="KC-TEST", caller="test", reason="unit_test")
    logging.info("--- Prometheus Oracle feature_orderãƒ†ã‚¹ãƒˆå®Œäº† ---")
