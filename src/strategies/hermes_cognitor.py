# src/strategies/hermes_cognitor.py
# -*- coding: utf-8 -*-
"""
ğŸ¦‰ Hermes Cognitor (feature_orderæº–æ‹ )
- Planå±¤ã®æ¨™æº–dict/feature_order/labelsã‚’è‡ªç„¶è¨€èªèª¬æ˜
- decision_id / caller / trace_id ã‚’è¿”å´
- å…±é€šSystem Prompt(v1.5) ã‚’å‰ç½®ã—ã€LLMï¼ˆOpenAIï¼‰å‘¼ã³å‡ºã—ã«å¯¾å¿œ
- LLMä¸å¯æ™‚ã¯å®‰å…¨ãªãƒ€ãƒŸãƒ¼è¦ç´„ã¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
- ç”Ÿæˆç‰©ã¯ agent_logsï¼ˆSQLite: src/codex_reports/pdca_log.dbï¼‰ã¸ä»»æ„ä¿å­˜
"""

from __future__ import annotations

import datetime as dt
import json
import logging
import os
import sqlite3
from pathlib import Path
from typing import Any, Dict, List, Optional

from src.plan_data.standard_feature_schema import STANDARD_FEATURE_ORDER

# å…±é€šSPãƒ­ãƒ¼ãƒ€
try:
    from codex.prompts.loader import load_noctria_system_prompt  # v1.5 ã‚’æƒ³å®š
except Exception:  # ãƒ­ãƒ¼ãƒ€æœªé…ç½®ã§ã‚‚å‹•ä½œã•ã›ã‚‹

    def load_noctria_system_prompt(_v: str) -> str:
        return "You are Noctria Kingdom common system prompt (fallback)."


# -----------------------------------------------------------------------------
# ãƒ­ã‚°è¨­å®š
# -----------------------------------------------------------------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s - [%(levelname)s] - %(message)s")
LOG = logging.getLogger("HermesCognitor")


# -----------------------------------------------------------------------------
# OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆé¸æŠï¼ˆæ–°APIå„ªå…ˆâ†’æ—§APIãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
# -----------------------------------------------------------------------------
def _choose_openai_client():
    api_key = os.getenv("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY_NOCTRIA")
    if not api_key:
        return None, None
    try:
        from openai import OpenAI  # type: ignore

        return "new", OpenAI(api_key=api_key)
    except Exception:
        try:
            import openai  # type: ignore

            openai.api_key = api_key
            return "old", openai
        except Exception:
            return None, None


# -----------------------------------------------------------------------------
# DBï¼ˆagent_logsï¼‰  â€»run_pdca_agents.py ã¨åŒãƒ†ãƒ¼ãƒ–ãƒ«äº’æ›
# -----------------------------------------------------------------------------
def _db_path() -> Path:
    root = Path(__file__).resolve().parents[2]  # project root
    return Path(os.getenv("NOCTRIA_PDCA_DB", str(root / "src" / "codex_reports" / "pdca_log.db")))


def _db_connect() -> Optional[sqlite3.Connection]:
    try:
        dbp = _db_path()
        dbp.parent.mkdir(parents=True, exist_ok=True)
        conn = sqlite3.connect(dbp)
        # æœ€ä½é™ã®ã‚¹ã‚­ãƒ¼ãƒï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã®ã¿è»½ãä½œæˆï¼‰
        conn.executescript(
            """
            CREATE TABLE IF NOT EXISTS agent_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                trace_id TEXT,
                role TEXT,
                title TEXT,
                content TEXT,
                created_at TEXT
            );
            """
        )
        return conn
    except Exception as e:
        LOG.warning("agent_logs DBæ¥ç¶šã«å¤±æ•—: %s", e)
        return None


def _db_log_agent(role: str, title: str, content: str, trace_id: Optional[str]) -> None:
    conn = _db_connect()
    if not conn:
        return
    try:
        jst = dt.timezone(dt.timedelta(hours=9))
        ts = dt.datetime.now(tz=jst).isoformat(timespec="seconds")
        conn.execute(
            "INSERT INTO agent_logs (trace_id, role, title, content, created_at) VALUES (?, ?, ?, ?, ?)",
            (trace_id or "", role, title, content, ts),
        )
        conn.commit()
    except Exception as e:
        LOG.warning("agent_logs ã¸ã®æ›¸ãè¾¼ã¿ã«å¤±æ•—: %s", e)
    finally:
        try:
            conn.close()
        except Exception:
            pass


# -----------------------------------------------------------------------------
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
# -----------------------------------------------------------------------------
COMMON_SP = load_noctria_system_prompt("v1.5")

HERMES_SYSTEM_PROMPT = (
    COMMON_SP
    + """

ã‚ãªãŸã¯ Noctria ç‹å›½ã®èª¬æ˜AIã€Hermes Cognitorã€ã§ã™ã€‚
å½¹å‰²:
- Planå±¤ã‹ã‚‰æ¸¡ã•ã‚Œã‚‹ç‰¹å¾´é‡(dict)ã¨ feature_orderã€è¦å› ãƒ©ãƒ™ãƒ«(labels)ã‚’ã‚‚ã¨ã«ã€
  æˆ¦ç•¥æ„å›³ãƒ»æ ¹æ‹ ãƒ»å‰æãƒ»ãƒªã‚¹ã‚¯ãƒ»æƒ³å®šã‚·ãƒŠãƒªã‚ªãƒ»æ’¤é€€æ¡ä»¶ã‚’ã€ç°¡æ½”ã‹ã¤å…·ä½“çš„ã«æ—¥æœ¬èªã§èª¬æ˜ã—ã¾ã™ã€‚
- ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºåˆ†æã¨ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æã®ä¸¡é¢ã‚’æ¥ç¶šã—ã€ç›¸äº’ã®æ•´åˆã‚’è¨€èªåŒ–ã—ã¾ã™ã€‚
- Fintokeiãƒãƒªã‚·ãƒ¼ï¼ˆã‚®ãƒ£ãƒ³ãƒ–ãƒ«çš„è¡Œç‚ºã®ç¦æ­¢ã€1ã‚¢ã‚¤ãƒ‡ã‚¢ã§ã®éå‰°ãƒªã‚¹ã‚¯>3%ã®ç¦æ­¢ã€å†ç¾æ€§é‡è¦–ï¼‰ã«åã—ãªã„åŠ©è¨€ã«é™å®šã—ã¾ã™ã€‚

å‡ºåŠ›æ–¹é‡:
- ç®‡æ¡æ›¸ãä¸­å¿ƒï¼ˆè¦‹å‡ºã—ï¼‹çŸ­æ–‡ï¼‰ã€‚æ–­å®šã‚ˆã‚Šç¢ºç‡/æ¡ä»¶è¨€åŠã‚’å¥½ã‚€ã€‚
- ã€Œãªãœãã®æŒ‡æ¨™ãŒæœ‰åŠ¹ã‹ã€ã€Œé€†ã‚·ãƒŠãƒªã‚ªã¯ä½•ã‹ã€ã€Œä½•ã§æ’¤é€€ã™ã‚‹ã‹ã€ã‚’å¿…ãšå«ã‚ã‚‹ã€‚
- ä½™è¨ˆãªç¾è¾éº—å¥ã¯ä¸è¦ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‰å®Ÿå‹™ã§ä½¿ã†ãŸã‚ã®ãƒ¡ãƒ¢ã«å¾¹ã™ã‚‹ã€‚

å‡ºåŠ›JSONã‚¹ã‚­ãƒ¼ãƒ:
{
  "summary": "1ã€œ2æ–‡ã®è¦ç´„",
  "rationale": ["æ ¹æ‹ 1", "æ ¹æ‹ 2", "..."],        // TA/FAã®ä¸¡è»¸ã‚’æ··ãœã¦OK
  "risk_notes": ["ä¸»è¦ãƒªã‚¹ã‚¯/ä»£æ›¿ã‚·ãƒŠãƒªã‚ª", "..."],
  "exit_rules": ["æ’¤é€€æ¡ä»¶(ä¾‹: SL/æ™‚é–“/ãƒ‹ãƒ¥ãƒ¼ã‚¹)", "..."],
  "assumptions": ["å‰æãƒ»å¿…è¦æ¡ä»¶", "..."],
  "notes": ["è£œè¶³(ãƒ‡ãƒ¼ã‚¿å“è³ª/ç›¸é–¢/ã‚¤ãƒ™ãƒ³ãƒˆæ³¨æ„)", "..."]
}
"""
)

DEFAULT_MODEL = os.getenv("NOCTRIA_GPT_MODEL") or os.getenv("OPENAI_MODEL") or "gpt-4o-mini"


# -----------------------------------------------------------------------------
# æœ¬ä½“
# -----------------------------------------------------------------------------
class HermesCognitorStrategy:
    def __init__(self, model: str = DEFAULT_MODEL, feature_order: Optional[List[str]] = None):
        self.model = model
        self.feature_order = feature_order or STANDARD_FEATURE_ORDER

    # ---- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰ ----
    def _build_user_prompt(
        self,
        features: Dict[str, Any],
        labels: List[str],
        feature_order: Optional[List[str]] = None,
        reason: Optional[str] = None,
    ) -> str:
        fo = feature_order or self.feature_order
        payload = {
            "feature_order": fo,
            "features": features,
            "labels": labels,
            "hint_reason": reason or "",
        }
        return (
            "æ¬¡ã®å…¥åŠ›ã‚’èª­ã¿ã€ä¸Šè¨˜ã® JSON ã‚¹ã‚­ãƒ¼ãƒã§è¿”ç­”ã—ã¦ãã ã•ã„ï¼ˆæ—¥æœ¬èªãƒ»JSONã®ã¿ï¼‰ã€‚\n"
            + json.dumps(payload, ensure_ascii=False)
        )

    # ---- LLMå‘¼ã³å‡ºã— ----
    def _call_llm(self, user_prompt: str) -> Optional[Dict[str, Any]]:
        mode, client = _choose_openai_client()
        if not client:
            return None
        try:
            if mode == "new":
                resp = client.chat.completions.create(  # type: ignore
                    model=self.model,
                    messages=[
                        {"role": "system", "content": HERMES_SYSTEM_PROMPT},
                        {"role": "user", "content": user_prompt},
                    ],
                    temperature=0.2,
                    response_format={"type": "json_object"},
                )
                txt = (resp.choices[0].message.content or "{}").strip()
            else:
                # æ—§API
                resp = client.ChatCompletion.create(  # type: ignore
                    model=self.model,
                    messages=[
                        {"role": "system", "content": HERMES_SYSTEM_PROMPT},
                        {"role": "user", "content": user_prompt},
                    ],
                    temperature=0.2,
                )
                txt = (resp["choices"][0]["message"]["content"] or "{}").strip()

            data = json.loads(txt)
            if not isinstance(data, dict):
                return None
            # æœ€ä½é™ã®ã‚­ãƒ¼è£œå®Œ
            data.setdefault("summary", "")
            data.setdefault("rationale", [])
            data.setdefault("risk_notes", [])
            data.setdefault("exit_rules", [])
            data.setdefault("assumptions", [])
            data.setdefault("notes", [])
            return data
        except Exception as e:
            LOG.warning("Hermes LLM å‘¼ã³å‡ºã—ã«å¤±æ•—: %s", e)
            return None

    # ---- ãƒ€ãƒŸãƒ¼ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ ----
    @staticmethod
    def _fallback_summary(labels: List[str]) -> Dict[str, Any]:
        head = labels[0] if labels else "ç‰¹å¾´é‡ãƒ»è¦å› ã‹ã‚‰ã®æˆ¦ç•¥èª¬æ˜"
        return {
            "summary": f"[ãƒ€ãƒŸãƒ¼è¦ç´„] {head}",
            "rationale": ["ãƒ‡ãƒ¼ã‚¿æŒ‡ç¤ºã«åŸºã¥ãçŸ­æœŸãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ /å¹³å‡å›å¸°ã®å¯èƒ½æ€§ã‚’è©•ä¾¡"],
            "risk_notes": ["ã‚¤ãƒ™ãƒ³ãƒˆæ€¥å¤‰ãƒ»é«˜ãƒœãƒ©éŠ˜æŸ„ã®ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸", "æƒ³å®šã¨é€†æ–¹å‘ã®æŒç¶šãƒˆãƒ¬ãƒ³ãƒ‰"],
            "exit_rules": ["äº‹å‰SLåˆ°é”", "æƒ³å®šãƒ‹ãƒ¥ãƒ¼ã‚¹å¦å®š", "æ™‚é–“çš„æ’¤é€€ï¼ˆå½“æ—¥ã‚¯ãƒ­ãƒ¼ã‚ºï¼‰"],
            "assumptions": ["ãƒ‡ãƒ¼ã‚¿ã®æ¬ æãƒ»é…å»¶ãŒé–¾å€¤å†…", "ç›¸é–¢ãƒ»é‡è¤‡ã‚·ã‚°ãƒŠãƒ«ãŒè¨±å®¹å†…"],
            "notes": ["å®Ÿé‹ç”¨ã¯ Noctus Gate ã®ãƒ­ãƒƒãƒˆãƒ»ãƒªã‚¹ã‚¯åˆ¶ç´„ã«å¾“ã†"],
        }

    # ---- å¤–éƒ¨APIï¼ˆPlanå±¤ï¼‰ ----
    def summarize_strategy(
        self,
        features: Dict[str, Any],
        labels: List[str],
        feature_order: Optional[List[str]] = None,
        reason: Optional[str] = None,
        trace_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        user_prompt = self._build_user_prompt(features, labels, feature_order, reason)
        LOG.info("HermesCognitor: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰å®Œäº† / model=%s", self.model)

        out = self._call_llm(user_prompt) or self._fallback_summary(labels)
        # agent_logs ã¸ä¿å­˜ï¼ˆä»»æ„ï¼‰
        try:
            _db_log_agent(
                role="hermes",
                title="Hermes Explanation",
                content=json.dumps(out, ensure_ascii=False),
                trace_id=trace_id,
            )
        except Exception:
            pass
        return out

    # ---- Strategyã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ ----
    def propose(
        self,
        input_data: Dict[str, Any],
        decision_id: Optional[str] = None,
        caller: Optional[str] = "king_noctria",
    ) -> Dict[str, Any]:
        features = input_data.get("features", {}) or {}
        labels = input_data.get("labels", []) or []
        feature_order = input_data.get("feature_order", self.feature_order)
        reason = input_data.get("reason", "")
        trace_id = input_data.get("trace_id")

        explanation_obj = self.summarize_strategy(
            features=features,
            labels=labels,
            feature_order=feature_order,
            reason=reason,
            trace_id=trace_id,
        )

        return {
            "name": "HermesCognitor",
            "type": "llm_explanation_report",
            "explanation": explanation_obj,  # â† JSONæ§‹é€ ã§è¿”ã™
            "feature_order": feature_order,
            "source_features": features,
            "labels": labels,
            "reason": reason,
            "llm_model": self.model,
            "decision_id": decision_id,
            "caller": caller,
            "trace_id": trace_id,
        }
