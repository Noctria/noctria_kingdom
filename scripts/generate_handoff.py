#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
scripts/generate_handoff.py

ç›´è¿‘ã®ã‚³ãƒŸãƒƒãƒˆã‚„é€²æ—ã‚’ã¾ã¨ã‚ã¦ handoff/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã« Markdown(+JSON) ã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
- --lookback-hours N : ç›´è¿‘Næ™‚é–“ã®æ›´æ–°ã‚’æŠ½å‡ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ24ï¼‰
- --next-from FILE   : æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.md/.txtï¼‰ã‹ã‚‰èª­ã¿è¾¼ã‚€ï¼ˆå„è¡Œã‚’1é …ç›®ï¼‰
- --auto-complete-next: æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®é”æˆçŠ¶æ³ã‚’ãƒªãƒã‚¸ãƒˆãƒªçŠ¶æ…‹ã‹ã‚‰è‡ªå‹•åˆ¤å®šã—ã¦ [x] ã«ã™ã‚‹ï¼ˆãƒ™ãƒ¼ã‚¹ã¯ --next-from / ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒªã‚¹ãƒˆï¼‰
- --include-airflow  : Airflow scheduler ã‚³ãƒ³ãƒ†ãƒŠå†…ã® /opt/airflow/backtests ã‚’èµ°æŸ»ã—ã€ç›´è¿‘Runsã®æˆæœç‰©çŠ¶æ³ã‚’è¿½è¨˜
- --airflow-container: ï¼ˆ--include-airflowæœ‰åŠ¹æ™‚ï¼‰å¯¾è±¡ã‚³ãƒ³ãƒ†ãƒŠåï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: noctria_airflow_schedulerï¼‰
- --max-runs         : ï¼ˆ--include-airflowæœ‰åŠ¹æ™‚ï¼‰ä¸€è¦§ã«è¼‰ã›ã‚‹æœ€å¤§ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰
"""

from __future__ import annotations
from pathlib import Path
import argparse
import subprocess
import datetime as dt
import json
import os
import shlex
from typing import List, Dict, Tuple, Optional

ROOT = Path(__file__).resolve().parents[1]
HANDOFF_DIR = ROOT / "handoff"
HANDOFF_DIR.mkdir(exist_ok=True)


# ------------------------
# Shell helpers
# ------------------------
def run(cmd: str, *, cwd: Path | None = None, check: bool = True) -> str:
    if cwd is None:
        cwd = ROOT
    try:
        return subprocess.check_output(shlex.split(cmd), text=True, cwd=str(cwd)).strip()
    except subprocess.CalledProcessError as e:
        if check:
            raise
        return e.output.strip() if e.output else ""


def command_exists(cmd: str) -> bool:
    """Return True if command exists on PATH."""
    try:
        subprocess.check_output(["bash", "-lc", f"command -v {shlex.quote(cmd)}"], text=True)
        return True
    except Exception:
        return False


# ------------------------
# Git
# ------------------------
def recent_commits(hours: int) -> List[Dict]:
    since = (dt.datetime.now() - dt.timedelta(hours=hours)).strftime("%Y-%m-%d %H:%M:%S")
    try:
        # ãƒãƒƒã‚·ãƒ¥ã€ã‚µãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€ç›¸å¯¾æ™‚åˆ»ã€æ—¥æ™‚
        fmt = r"%h|%s|%cr|%cd"
        out = run(f'git log --since="{since}" --pretty=format:{fmt} --date=iso', check=False)
        lines = [ln for ln in out.splitlines() if ln.strip()]
    except Exception:
        lines = []
    commits = []
    for ln in lines:
        parts = ln.split("|", 3)
        if len(parts) == 4:
            h, subj, rel, ts = parts
            commits.append({"hash": h, "title": subj, "when": rel, "timestamp": ts})
    return commits


# ------------------------
# Next actions
# ------------------------
DEFAULT_NEXT_ACTIONS = [
    "DAG æœ¬å‡¦ç†ã®çµ„ã¿è¾¼ã¿",
    "æˆ¦ç•¥æŒ‡å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¯¾å¿œ",
    "çµæœã® artifact / PR ã‚³ãƒ¡ãƒ³ãƒˆå‡ºåŠ›",
]


def read_next_actions(path: str | None) -> List[str]:
    if not path:
        return list(DEFAULT_NEXT_ACTIONS)
    p = Path(path)
    if not p.exists():
        return [f"(next-from ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path})"]
    items: List[str] = []
    for ln in p.read_text(encoding="utf-8").splitlines():
        ln = ln.strip("-â€¢ ").strip()
        if ln:
            items.append(ln)
    return items or ["(æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒç©º)"]


def file_contains(path: Path, needle: str) -> bool:
    if not path.exists() or not path.is_file():
        return False
    try:
        txt = path.read_text(encoding="utf-8", errors="ignore")
        return needle in txt
    except Exception:
        return False


def auto_complete_next(actions: List[str]) -> List[Tuple[str, bool]]:
    """
    ç°¡æ˜“ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã§å®Œäº†åˆ¤å®šã€‚
    æˆ»ã‚Šå€¤: [(action_text, done_bool), ...]
    """
    dag_path = ROOT / "airflow_docker" / "dags" / "noctria_backtest_dag.py"
    scripts_dir = ROOT / "scripts"
    repo_veritas = ROOT / "airflow_docker" / "scripts" / "veritas_local_test.py"
    repo_veritas_alt = ROOT / "scripts" / "veritas_local_test.py"  # ç‰‡æ–¹ã«ã‚ã‚‹ã‚±ãƒ¼ã‚¹ã‚‚

    # 1) DAG æœ¬å‡¦ç†ã®çµ„ã¿è¾¼ã¿ï¼ˆrender_report ã‚¿ã‚¹ã‚¯ãŒå­˜åœ¨ï¼†report.html ã‚’æ›¸ã„ã¦ã„ã‚‹ï¼‰
    dag_has_render_task = file_contains(dag_path, "render_report") and file_contains(
        dag_path, "report.html"
    )

    # 2) æˆ¦ç•¥æŒ‡å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¯¾å¿œï¼ˆDAG ã§ NOCTRIA_STRATEGY_GLOB / NOCTRIA_EXTRA_ARGS ã‚’è¨­å®šã—å®Ÿè¡Œã¸æ¸¡ã™ï¼‰
    dag_sets_env = file_contains(dag_path, "NOCTRIA_STRATEGY_GLOB") and file_contains(
        dag_path, "NOCTRIA_EXTRA_ARGS"
    )
    # å®Ÿã‚¹ã‚¯ãƒªãƒ—ãƒˆå´ãŒç’°å¢ƒå¤‰æ•° or å¼•æ•°ã‚’èª­ã‚€å®Ÿè£…ã‹ã¯å³å¯†ã«ã¯ã‚½ãƒ¼ã‚¹ä¾å­˜ã€‚ã“ã“ã§ã¯å­˜åœ¨ã®ç—•è·¡ã ã‘è»½ãè¦‹ã‚‹
    script_consumes_env = any(
        [
            file_contains(repo_veritas, "NOCTRIA_STRATEGY_GLOB")
            or file_contains(repo_veritas, "NOCTRIA_EXTRA_ARGS"),
            file_contains(repo_veritas_alt, "NOCTRIA_STRATEGY_GLOB")
            or file_contains(repo_veritas_alt, "NOCTRIA_EXTRA_ARGS"),
            # ã‚‚ã—ãã¯ scripts/backtest_runner.py ãŒå—ã‘å–ã£ã¦ã„ã‚‹
            file_contains(scripts_dir / "backtest_runner.py", "NOCTRIA_STRATEGY_GLOB")
            or file_contains(scripts_dir / "backtest_runner.py", "NOCTRIA_EXTRA_ARGS"),
        ]
    )
    strategy_params_ready = dag_sets_env and script_consumes_env

    # 3) çµæœã® artifact / PR ã‚³ãƒ¡ãƒ³ãƒˆå‡ºåŠ›ï¼ˆGitHub Actions ã§ artifact or ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ï¼‰
    gh_wf_dir = ROOT / ".github" / "workflows"
    any_wf = list(gh_wf_dir.glob("*.yml")) + list(gh_wf_dir.glob("*.yaml"))
    artifact_or_comment = False
    for wf in any_wf:
        if (
            file_contains(wf, "upload-artifact")
            or file_contains(wf, "github-script")
            or file_contains(wf, "Create or update comment")
            or file_contains(wf, "issue_comment")
        ):
            artifact_or_comment = True
            break

    results: List[Tuple[str, bool]] = []
    for a in actions:
        done = False
        if "DAG æœ¬å‡¦ç†" in a:
            done = dag_has_render_task
        elif "æˆ¦ç•¥æŒ‡å®š" in a:
            done = strategy_params_ready
        elif "artifact" in a.lower() or "PR ã‚³ãƒ¡ãƒ³ãƒˆ" in a:
            done = artifact_or_comment
        results.append((a, done))
    return results


# ------------------------
# Airflow backtests (optional)
# ------------------------
def list_backtests_in_container(container: str, max_runs: int = 5) -> List[Dict]:
    """
    docker exec ã§ /opt/airflow/backtests ã‚’è¦—ãã€‚
    è¿”å´: [{"run_id": ..., "has_conf": bool, "has_result": bool, "has_html": bool, "has_stdout": bool}, ...]
    æ–°ã—ã„é †ã®ã¤ã‚‚ã‚Šã§ ls -1t ã‚’ä½¿ç”¨ã€‚
    """
    if not command_exists("docker"):
        return []
    try:
        base = "/opt/airflow/backtests"
        # ç›´è¿‘ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ–°ã—ã„é †ã«
        dirs = run(
            f'docker exec {shlex.quote(container)} bash -lc "ls -1t {base} 2>/dev/null | head -n {int(max_runs)}"',
            check=False,
        )
        run_ids = [d.strip() for d in dirs.splitlines() if d.strip()]
        results: List[Dict] = []
        for rid in run_ids:

            def exists(p: str) -> bool:
                code = subprocess.call(
                    ["docker", "exec", container, "bash", "-lc", f"test -f {shlex.quote(p)}"],
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL,
                )
                return code == 0

            outdir = f"{base}/{rid}"
            results.append(
                {
                    "run_id": rid,
                    "has_conf": exists(f"{outdir}/conf.json"),
                    "has_result": exists(f"{outdir}/result.json"),
                    "has_html": exists(f"{outdir}/report.html"),
                    "has_stdout": exists(f"{outdir}/stdout.txt"),
                }
            )
        return results
    except Exception:
        return []


# ------------------------
# Main
# ------------------------
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--lookback-hours", type=int, default=24)
    ap.add_argument("--next-from", type=str, default=None)
    ap.add_argument(
        "--auto-complete-next", action="store_true", help="æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è‡ªå‹•åˆ¤å®šã—ã¦ [x] ã‚’ä»˜ã‘ã‚‹"
    )
    ap.add_argument(
        "--include-airflow", action="store_true", help="Airflow ã® backtests ä¸€è¦§ã‚’ä»˜è¨˜ã™ã‚‹"
    )
    ap.add_argument("--airflow-container", type=str, default="noctria_airflow_scheduler")
    ap.add_argument("--max-runs", type=int, default=5)
    args = ap.parse_args()

    now = dt.datetime.now()
    now_str = now.strftime("%Y-%m-%d %H:%M:%S")
    date_tag = now.date().isoformat()

    md_path = HANDOFF_DIR / f"handoff_{date_tag}.md"
    json_path = HANDOFF_DIR / f"handoff_{date_tag}.json"

    commits = recent_commits(args.lookback_hours)
    base_actions = read_next_actions(args.next_from)

    # è‡ªå‹•åˆ¤å®šã§ãƒã‚§ãƒƒã‚¯çŠ¶æ…‹ã‚’ä»˜ã‘ã‚‹
    if args.auto_complete_next:
        actions_with_state = auto_complete_next(base_actions)
    else:
        actions_with_state = [(a, False) for a in base_actions]

    # Airflow ã® backtests ä¸€è¦§ï¼ˆä»»æ„ï¼‰
    airflow_runs: List[Dict] = []
    if args.include_airflow:
        airflow_runs = list_backtests_in_container(args.airflow_container, args.max_runs)

    data = {
        "generated_at": now_str,
        "lookback_hours": args.lookback_hours,
        "commits": commits,
        "next_actions": [{"text": a, "done": d} for a, d in actions_with_state],
        "airflow_runs": airflow_runs,
    }

    # Markdownç”Ÿæˆ
    md: List[str] = []
    md.append(f"# ğŸ“ å¼•ãç¶™ããƒ¬ãƒãƒ¼ãƒˆ ({now_str})")
    md.append(f"_ç›´è¿‘ **{args.lookback_hours}h** ã®æ›´æ–°ã‚’é›†è¨ˆ_\n")

    # Recent commits
    md.append("## âœ… æœ€è¿‘ã®ã‚³ãƒŸãƒƒãƒˆ")
    if not commits:
        md.append("- ï¼ˆè©²å½“ãªã—ï¼‰")
    else:
        for c in commits:
            md.append(f"- {c['hash']} {c['title']} ({c['when']})")

    # Next actions
    md.append("\n## ğŸš© æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    for a, done in actions_with_state:
        mark = "x" if done else " "
        md.append(f"- [{mark}] {a}")

    # Airflow runs (optional)
    if args.include_airflow:
        md.append("\n## ğŸ§ª Airflow Backtestsï¼ˆç›´è¿‘ï¼‰")
        if not airflow_runs:
            md.append("- ï¼ˆè©²å½“ãªã— / ã‚‚ã—ãã¯ docker æœªæ¤œå‡ºï¼‰")
        else:
            for r in airflow_runs:
                flags = []
                flags.append("confâœ…" if r.get("has_conf") else "confâ€”")
                flags.append("resultâœ…" if r.get("has_result") else "resultâ€”")
                flags.append("htmlâœ…" if r.get("has_html") else "htmlâ€”")
                flags.append("stdoutâœ…" if r.get("has_stdout") else "stdoutâ€”")
                md.append(f"- `{r['run_id']}` : " + ", ".join(flags))

    # æ©Ÿæ¢°å¯èª­ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆè²¼ä»˜æ™‚ã‚‚æŠ½å‡ºã§ãã‚‹ï¼‰
    md.append("\n<!--HANDOFF_JSON")
    md.append(json.dumps(data, ensure_ascii=False))
    md.append("HANDOFF_JSON-->")

    md_path.write_text("\n".join(md) + "\n", encoding="utf-8")
    json_path.write_text(json.dumps(data, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")

    print(f"âœ… Handoff written:\n- {md_path}\n- {json_path}")


if __name__ == "__main__":
    main()
