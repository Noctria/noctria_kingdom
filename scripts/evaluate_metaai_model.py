from core.path_config import CORE_DIR, DAGS_DIR, DATA_DIR, INSTITUTIONS_DIR, LOGS_DIR, MODELS_DIR, PLUGINS_DIR, SCRIPTS_DIR, STRATEGIES_DIR, TESTS_DIR, TOOLS_DIR, VERITAS_DIR
# coding: utf-8

from core.path_config import MODELS_DIR, DATA_DIR, LOGS_DIR
from core.meta_ai_env_with_fundamentals import TradingEnvWithFundamentals
from stable_baselines3 import PPO
import os

def evaluate_metaai_model():
    model_path = MODELS_DIR / "latest" / "metaai_model_latest.zip"
    data_path = DATA_DIR / "preprocessed_usdjpy_with_fundamental.csv"

    if not model_path.exists():
        print(f"‚ùå „É¢„Éá„É´„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì: {model_path}")
        return

    print(f"üì• „É¢„Éá„É´Ë™≠Ëæº: {model_path}")
    model = PPO.load(str(model_path))

    env = TradingEnvWithFundamentals(str(data_path))
    obs = env.reset()
    total_reward = 0
    done = False

    while not done:
        action, _states = model.predict(obs)
        obs, reward, done, info = env.step(action)
        total_reward += reward

    print(f"‚úÖ Ë©ï‰æ°ÂÆå‰∫Ü: Á¥ØÁ©çÂ†±ÈÖ¨ = {total_reward}")
    result_path = LOGS_DIR / "metaai_evaluation_result.txt"
    with open(result_path, "w") as f:
        f.write(f"Total reward: {total_reward}\n")