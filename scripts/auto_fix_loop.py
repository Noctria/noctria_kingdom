#!/usr/bin/env python3
"""
Auto-fix loop (PDCAå¼·åŒ–ç‰ˆ)
- å¤±æ•—æŒ‡ç´‹(YAML)â†’ä¿®æ­£ã‚¬ã‚¤ãƒ‰æ³¨å…¥
- å¿…é ˆãƒˆãƒ¼ã‚¯ãƒ³æ¤œæŸ»(ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥)
- Few-shot ä¾‹ã®è‡ªå‹•æ³¨å…¥
- æ®µéšãƒ†ã‚¹ãƒˆ(è»½â†’é‡) + å·®åˆ†ãƒ†ã‚¹ãƒˆ
- æˆæœãƒ¡ãƒˆãƒªã‚¯ã‚¹(JSONL)è¨˜éŒ²
- è¿½åŠ : æ¸©åº¦0.0 / ãƒˆãƒ¬ãƒ¼ã‚¹Allowlist / å›å¸°ã‚²ãƒ¼ãƒˆ(å¤±æ•—æ™‚ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯, æˆåŠŸæ™‚ã®ã¿commit)

Usage:
  OPENAI_API_KEY=sk-... python scripts/auto_fix_loop.py --max-iters 5

ç’°å¢ƒå¤‰æ•°:
  NOCTRIA_AUTOFIX_MODEL  : ãƒ¢ãƒ‡ãƒ«å (default: gpt-4o-mini)
  NOCTRIA_AUTOFIX_LIGHT  : "1" ãªã‚‰è»½ãƒ†ã‚¹ãƒˆå„ªå…ˆ (default: 1)
  NOCTRIA_AUTOFIX_RUFF   : "1" ãªã‚‰ ruff --fix å®Ÿè¡Œ (default: 1)
  NOCTRIA_AUTOFIX_BLACK  : "1" ãªã‚‰ black å®Ÿè¡Œ (default: 1)
  NOCTRIA_AUTOFIX_COMMIT : "1" ãªã‚‰ git commit (default: 1; â€»æˆåŠŸæ™‚ã®ã¿å®Ÿæ–½)
"""

from __future__ import annotations
import argparse
import json
import os
import re
import shutil
import subprocess
import sys
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Set

# ===================== è¨­å®š =====================

ROOT = Path(__file__).resolve().parents[1]
ALLOWED_DIRS = ("src/", "tests/")
MODEL = os.getenv("NOCTRIA_AUTOFIX_MODEL", "gpt-4o-mini")
MAX_ITERS = 5

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»å‡ºåŠ›ã‚µã‚¤ã‚ºã‚¬ãƒ¼ãƒ‰
CTX_MAX_BYTES = 160_000
MAX_PATCH_BYTES = 300_000
MAX_TOTAL_PATCH_BYTES = 600_000

# å®Ÿè¡Œãƒ•ãƒ©ã‚°
RUN_RUFF = os.getenv("NOCTRIA_AUTOFIX_RUFF", "1") == "1"
RUN_BLACK = os.getenv("NOCTRIA_AUTOFIX_BLACK", "1") == "1"
GIT_COMMIT = os.getenv("NOCTRIA_AUTOFIX_COMMIT", "1") == "1"
LIGHT_FIRST = os.getenv("NOCTRIA_AUTOFIX_LIGHT", "1") == "1"

# ãƒ–ãƒ©ãƒ³ãƒ
BRANCH_PREFIX = "autofix"

# è¿½åŠ ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå¸¸ã«æ–‡è„ˆã«å«ã‚ã‚‹ï¼‰
EXTRA_CONTEXT_FILES = [
    "pytest.ini",
    "pyproject.toml",
    "tests/conftest.py",
    "src/core/path_config.py",
]

# å¤±æ•—æŒ‡ç´‹ãƒ»å¿…é ˆãƒˆãƒ¼ã‚¯ãƒ³ãƒ»Few-shot è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
FINGERPRINTS_YAML = ROOT / "scripts" / "autofix_fingerprints.yaml"
REQUIRED_TOKENS_JSON = ROOT / "scripts" / "autofix_required_tokens.json"
FEWSHOT_DIR = ROOT / "scripts" / "autofix_fewshots"

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜å…ˆ
METRICS_JSONL = ROOT / "src" / "codex_reports" / "autofix_metrics.jsonl"

# ===================== ãƒ˜ãƒ«ãƒ‘ =====================


@dataclass
class PytestResult:
    ok: bool
    code: int
    stdout: str
    stderr: str


def run(cmd: List[str], check=False, **kw) -> subprocess.CompletedProcess:
    return subprocess.run(cmd, text=True, capture_output=True, check=check, **kw)


def run_pytest(light: bool, target_tests: Optional[List[str]] = None) -> PytestResult:
    """
    light=True: æ—¢å®šè¨­å®š(heavy/gpu/external ã‚’ skip ã™ã‚‹ pytest.ini å‰æ) + å·®åˆ†ãƒ†ã‚¹ãƒˆå„ªå…ˆ
    light=False: å¯èƒ½ãªã‚‰é‡ã‚å…¨ä½“å®Ÿè¡Œ
    """
    base = ["pytest", "-q", "--maxfail=1", "--disable-warnings", "-rA"]
    args = base[:]
    if target_tests:
        args += target_tests
    proc = run(args, check=False)
    return PytestResult(
        ok=(proc.returncode == 0), code=proc.returncode, stdout=proc.stdout, stderr=proc.stderr
    )


TB_FILE_RE = re.compile(r'File "([^"]+)", line (\d+), in ([^\n]+)')


def extract_trace_files(stdout: str, stderr: str, limit: int = 12) -> List[Tuple[Path, int, str]]:
    text = "\n".join([stdout[-30000:], stderr[-30000:]])
    hits = TB_FILE_RE.findall(text)
    out: List[Tuple[Path, int, str]] = []
    for fp, line, fn in hits[:limit]:
        p = Path(fp)
        try:
            ln = int(line)
        except Exception:
            ln = 1
        out.append((p, ln, fn))
    return out


def read_snippet(p: Path, around_line: int, radius: int = 36) -> Optional[str]:
    if not p.exists() or not p.is_file():
        return None
    try:
        lines = p.read_text(encoding="utf-8", errors="ignore").splitlines()
    except Exception:
        return None
    i0 = max(0, around_line - radius - 1)
    i1 = min(len(lines), around_line + radius)
    snippet = []
    for idx in range(i0, i1):
        prefix = ">>" if (idx + 1) == around_line else "  "
        snippet.append(f"{prefix}{idx+1:5d}: {lines[idx]}")
    return "\n".join(snippet)


def collect_repo_context(
    trace_files: List[Tuple[Path, int, str]], extra_files: List[str] | None = None
) -> Dict:
    ctx_items = []
    added: set[str] = set()
    for p, ln, fn in trace_files:
        if not p.exists() or p.suffix not in (".py", ".toml", ".ini", ".cfg", ".yaml", ".yml"):
            continue
        key = str(p)
        if key in added:
            continue
        snippet = read_snippet(p, ln) or ""
        added.add(key)
        ctx_items.append({"path": key, "around_line": ln, "function": fn, "snippet": snippet})
    for extra in extra_files or []:
        pe = Path(extra)
        if pe.exists() and pe.is_file() and str(pe) not in added:
            try:
                txt = pe.read_text(encoding="utf-8", errors="ignore")
            except Exception:
                txt = ""
            ctx_items.append(
                {"path": str(pe), "around_line": 1, "function": "", "snippet": txt[:10000]}
            )
            added.add(str(pe))
    payload = json.dumps(ctx_items, ensure_ascii=False)
    if len(payload.encode("utf-8")) > CTX_MAX_BYTES:
        ctx_items = ctx_items[: max(1, len(ctx_items) // 2)]
    return {"files": ctx_items}


def detect_changed_tests_from_patches(patches: List[Dict]) -> List[str]:
    """
    ãƒ‘ãƒƒãƒã«å¯¾å¿œã™ã‚‹ãƒ†ã‚¹ãƒˆã‚’ç°¡æ˜“ã«æ¨å®šã€‚
    - tests/ ä¸‹ã®ç›´æ¥ãƒ‘ãƒƒãƒã¯ãã®ã¾ã¾å¯¾è±¡
    - src/xxx.py ã«å¯¾ã—ã¦ã¯ tests/xxx*_test.py, tests/test_*xxx*.py ã‚’å€™è£œã«
    """
    candidates: set[str] = set()
    for p in patches:
        path = p.get("path", "")
        if not path:
            continue
        if path.startswith("tests/") and path.endswith(".py"):
            candidates.add(path)
        elif path.startswith("src/") and path.endswith(".py"):
            stem = Path(path).stem
            for pat in [f"tests/{stem}*_test.py", f"tests/test_*{stem}*.py"]:
                for m in ROOT.glob(pat):
                    candidates.add(str(m.relative_to(ROOT)))
    return sorted(candidates)


# ===== Allowlist: ãƒˆãƒ¬ãƒ¼ã‚¹ã«å‡ºãŸãƒ‘ã‚¹ã®ã¿è¨±å¯ï¼ˆsrc/, tests/ é…ä¸‹ã«é™ã‚‹ï¼‰ =====


def build_trace_allowlist(trace_files: List[Tuple[Path, int, str]]) -> Set[str]:
    allow: Set[str] = set()
    for p, _, _ in trace_files:
        try:
            rel = str(p.relative_to(ROOT))
        except Exception:
            rel = str(p)
        if any(rel.startswith(d) for d in ALLOWED_DIRS):
            allow.add(rel)
    return allow


# ===================== å¤±æ•—æŒ‡ç´‹ / å¿…é ˆãƒˆãƒ¼ã‚¯ãƒ³ / Few-shot =====================


def load_fingerprints() -> List[Dict]:
    try:
        import yaml  # type: ignore
    except Exception:
        return []
    if not FINGERPRINTS_YAML.exists():
        return []
    try:
        data = yaml.safe_load(FINGERPRINTS_YAML.read_text(encoding="utf-8"))
        return data or []
    except Exception:
        return []


def match_fingerprints(stdout: str, stderr: str) -> List[Dict]:
    fps = load_fingerprints()
    text = "\n".join([stdout[-40000:], stderr[-40000:]])
    out: List[Dict] = []
    for f in fps:
        pat = f.get("when_stdout_regex") or f.get("when_stderr_regex")
        if not pat:
            continue
        try:
            if re.search(pat, text, re.S | re.M):
                out.append(f)
        except re.error:
            pass
    return out


def load_required_tokens() -> Dict[str, List[str]]:
    if not REQUIRED_TOKENS_JSON.exists():
        return {}
    try:
        return json.loads(REQUIRED_TOKENS_JSON.read_text(encoding="utf-8"))
    except Exception:
        return {}


def load_fewshots() -> List[Dict]:
    fewshots: List[Dict] = []
    if not FEWSHOT_DIR.exists():
        return fewshots
    for f in FEWSHOT_DIR.glob("*.jsonl"):
        try:
            for ln in f.read_text(encoding="utf-8").splitlines():
                ln = ln.strip()
                if not ln:
                    continue
                try:
                    obj = json.loads(ln)
                    if isinstance(obj, dict) and "patch" in obj:
                        fewshots.append(obj)
                except Exception:
                    continue
        except Exception:
            continue
    return fewshots[:6]


# ===================== ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ =====================

PROMPT_SYSTEM = """You are a senior Python engineer running an automated test-fixing loop.
You must ONLY return JSON that conforms to the requested schema. Do not include markdown fences or prose.
Constraints:
- Change ONLY files under these directories: {allowed_dirs}.
- Prefer minimal, surgical fixes.
- Output entire-file replacements (new content) instead of partial diffs.
- Keep code safe for offline CI (no network calls unless guarded/stubbed).
- Be careful with indentation, encoding, and imports placement.
- If the root cause is in tests vs src, fix whichever is clearly wrong; otherwise prefer src.
"""

PROMPT_USER_FMT = """Repository failing test summary:
Exit code: {code}

=== Pytest stdout (tail) ===
{stdout_tail}

=== Pytest stderr (tail) ===
{stderr_tail}

Files mentioned in tracebacks (with snippets):
{ctx_json}

Known failure fingerprints and guides (matched):
{fingerprints_json}

Few-shot examples (trimmed):
{fewshots_json}

Task:
- Propose one or more patches to make the failing test(s) pass.
- Return pure JSON with this schema:

{
  "reason": "short explanation",
  "patches": [
    {
      "path": "relative/path/under/src_or_tests.py",
      "new_content": "FULL new file content (UTF-8)",
      "why": "what changed"
    }
  ]
}

Rules:
- Only include files under {allowed_dirs}.
- Each "new_content" must be the complete new content for that file.
- No placeholders. No backticks.
- If you are not confident, return "patches": [] with a helpful "reason".
"""

# ===================== ãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—ï¼ˆå …ç‰¢åŒ– + æ¸©åº¦0.0ï¼‰ =====================


def call_model(user_prompt: str) -> Dict:
    """
    OpenAI SDK ã®å·®ç•°ã«è€ãˆã‚‹å®Ÿè£…:
    1) responses.parse (æ–°) ãŒã‚ã‚Œã°ä½¿ã†
    2) chat.completions with response_format={"type":"json_object"}
    3) responses.create + æ‰‹ãƒ‘ãƒ¼ã‚¹
    ã™ã¹ã¦ temperature=0.0ï¼ˆæ±ºå®šæ€§é‡è¦–ï¼‰
    """
    try:
        from openai import OpenAI
    except Exception:
        print("ERROR: openai package not installed. `pip install openai`", file=sys.stderr)
        raise

    client = OpenAI()
    system_msg = PROMPT_SYSTEM.format(allowed_dirs=list(ALLOWED_DIRS))

    # Path A: responses.parse
    try:
        resp = client.responses.parse(
            model=MODEL,
            input=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_prompt},
            ],
            **{"response_format": {"type": "json_object"}},
            temperature=0.0,
        )
        txt = resp.output_text
        return json.loads(txt)
    except Exception:
        pass

    # Path B: chat.completions
    try:
        cc = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.0,
            response_format={"type": "json_object"},
        )
        txt = cc.choices[0].message.content
        return json.loads(txt)
    except Exception:
        pass

    # Path C: responses.createï¼ˆæ‰‹ãƒ‘ãƒ¼ã‚¹ï¼‰
    try:
        resp = client.responses.create(
            model=MODEL,
            temperature=0.0,
            input=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_prompt},
            ],
        )
        txt = getattr(resp, "output_text", None)
        if not txt:
            parts = []
            for item in getattr(resp, "output", []) or []:
                if hasattr(item, "content"):
                    parts.extend(
                        [c.text for c in item.content if getattr(c, "type", "") == "output_text"]
                    )
            txt = "\n".join(parts) if parts else ""
        return json.loads(txt)
    except Exception as e:
        return {"reason": f"model call failed: {e!r}", "patches": []}


# ===================== æ¤œè¨¼ãƒ»é©ç”¨ãƒ»ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹ =====================


def validate_patches(
    patches: List[Dict],
    required_tokens: Dict[str, List[str]],
    allowed_paths: Optional[Set[str]] = None,
) -> Tuple[List[Dict], List[str]]:
    """
    - ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªAllowlistï¼ˆsrc/testsï¼‰
    - ãƒˆãƒ¬ãƒ¼ã‚¹Allowlistï¼ˆallowed_paths ãŒä¸ãˆã‚‰ã‚ŒãŸã‚‰ã€ãã®ä¸­ã ã‘è¨±å¯ï¼‰
    - å¿…é ˆãƒˆãƒ¼ã‚¯ãƒ³æ¤œæŸ»
    - ã‚µã‚¤ã‚ºã‚¬ãƒ¼ãƒ‰
    """
    errors: List[str] = []
    total_bytes = 0
    valid: List[Dict] = []

    for i, p in enumerate(patches):
        path = p.get("path", "")
        new_content = p.get("new_content", "")
        if not path or not isinstance(path, str):
            errors.append(f"[{i}] missing/invalid path")
            continue
        if not any(path.startswith(d) for d in ALLOWED_DIRS):
            errors.append(f"[{i}] path not allowed: {path}")
            continue
        if allowed_paths is not None and path not in allowed_paths:
            errors.append(f"[{i}] path not in traceback allowlist: {path}")
            continue

        b = len(new_content.encode("utf-8", errors="ignore"))
        if b == 0:
            errors.append(f"[{i}] empty content for {path}")
            continue
        if b > MAX_PATCH_BYTES:
            errors.append(f"[{i}] single patch too large ({b} bytes)")
            continue

        # å¿…é ˆãƒˆãƒ¼ã‚¯ãƒ³æ¤œæŸ»
        req = required_tokens.get(path) or required_tokens.get(str(Path(path)))
        if not req:
            from fnmatch import fnmatch

            for key, toks in required_tokens.items():
                if "*" in key or "?" in key:
                    if fnmatch(path, key):
                        req = toks
                        break
        if req:
            missing = [tok for tok in req if tok not in new_content]
            if missing:
                errors.append(f"[{i}] required tokens missing in {path}: {missing}")
                continue

        total_bytes += b
        valid.append({"path": path, "new_content": new_content, "why": p.get("why", "")})

    if total_bytes > MAX_TOTAL_PATCH_BYTES:
        errors.append(f"total patches too large ({total_bytes} bytes)")
        valid = []
    return valid, errors


def apply_patches_with_backups(patches: List[Dict]) -> List[Tuple[Path, Optional[Path]]]:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã« .autofix.bak ã‚’ä½œã£ã¦ã‹ã‚‰ä¸Šæ›¸ãã€‚
    è¿”ã‚Šå€¤: [(path, backup_path_or_None), ...]
    """
    applied: List[Tuple[Path, Optional[Path]]] = []
    for p in patches:
        path = Path(p["path"])
        path.parent.mkdir(parents=True, exist_ok=True)
        backup: Optional[Path] = None
        if path.exists():
            backup = path.with_suffix(path.suffix + ".autofix.bak")
            try:
                shutil.copy2(path, backup)
            except Exception:
                backup = None
        path.write_text(p["new_content"], encoding="utf-8")
        applied.append((path, backup))
    return applied


def format_code() -> None:
    if RUN_RUFF:
        run(["ruff", "check", "--fix", "src", "tests"], check=False)
    if RUN_BLACK:
        run(["black", "src", "tests"], check=False)


def rollback_files(applied: List[Tuple[Path, Optional[Path]]]) -> None:
    """
    ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒã‚ã‚Œã°å¾©å…ƒã€‚ãªã‘ã‚Œã°å‰Šé™¤ï¼ˆæ–°è¦ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å–ã‚Šæ¶ˆã—ï¼‰ã€‚
    """
    for path, backup in applied:
        try:
            if backup and backup.exists():
                shutil.copy2(backup, path)
                backup.unlink(missing_ok=True)
            else:
                # æ–°è¦ä½œæˆãªã‚‰å‰Šé™¤
                if path.exists():
                    path.unlink()
        except Exception:
            pass


def finalize_backups(applied: List[Tuple[Path, Optional[Path]]]) -> None:
    """æˆåŠŸç¢ºå®šå¾Œã« .autofix.bak ã‚’æƒé™¤ã€‚"""
    for _, backup in applied:
        if backup and backup.exists():
            try:
                backup.unlink()
            except Exception:
                pass


def git_commit(message: str) -> None:
    run(["git", "add", "-A"], check=False)
    run(["git", "commit", "-m", message], check=False)


def log_metrics(payload: Dict) -> None:
    try:
        METRICS_JSONL.parent.mkdir(parents=True, exist_ok=True)
        with METRICS_JSONL.open("a", encoding="utf-8") as f:
            f.write(json.dumps(payload, ensure_ascii=False) + "\n")
    except Exception:
        pass


# ===================== ãƒ¡ã‚¤ãƒ³ =====================


def ensure_branch():
    if not GIT_COMMIT:
        return
    ts = time.strftime("%Y%m%d_%H%M%S")
    name = f"{BRANCH_PREFIX}/{ts}"
    base = run(["git", "rev-parse", "--abbrev-ref", "HEAD"]).stdout.strip()
    res = run(["git", "checkout", "-b", name])
    if res.returncode != 0:
        print(f"[warn] could not create branch {name}, staying on {base}")


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--max-iters", type=int, default=MAX_ITERS)
    args = ap.parse_args()

    ensure_branch()
    required_tokens = load_required_tokens()
    fewshots = load_fewshots()

    for it in range(1, args.max_iters + 1):
        print(f"\n=== Iteration {it} ===")

        # ã¾ãšè»½ãƒ†ã‚¹ãƒˆ
        start_ts = time.time()
        res_light = run_pytest(light=True)
        light_elapsed = time.time() - start_ts

        if res_light.ok:
            # è»½ãƒ†ã‚¹ãƒˆGREENãªã‚‰é‡ãƒ†ã‚¹ãƒˆï¼ˆå¿…è¦ãªã‚‰ï¼‰
            if LIGHT_FIRST:
                start_ts2 = time.time()
                res_heavy = run_pytest(light=False)
                heavy_elapsed = time.time() - start_ts2
                if res_heavy.ok:
                    print("âœ… GREEN â€” all tests passed.")
                    log_metrics(
                        {
                            "ts": int(time.time()),
                            "iter": it,
                            "result": "GREEN",
                            "model": MODEL,
                            "light_elapsed_sec": round(light_elapsed, 3),
                            "heavy_elapsed_sec": round(heavy_elapsed, 3),
                            "patches": 0,
                        }
                    )
                    return
                stdout_tail = res_heavy.stdout[-20000:]
                stderr_tail = res_heavy.stderr[-20000:]
                trace_files = extract_trace_files(res_heavy.stdout, res_heavy.stderr)
            else:
                print("âœ… GREEN â€” (light tests).")
                log_metrics(
                    {
                        "ts": int(time.time()),
                        "iter": it,
                        "result": "GREEN_LIGHT_ONLY",
                        "model": MODEL,
                        "light_elapsed_sec": round(light_elapsed, 3),
                        "patches": 0,
                    }
                )
                return
        else:
            stdout_tail = res_light.stdout[-20000:]
            stderr_tail = res_light.stderr[-20000:]
            trace_files = extract_trace_files(res_light.stdout, res_light.stderr)

        # æ–‡è„ˆåé›† & Allowlist
        fps = match_fingerprints(stdout_tail, stderr_tail)
        ctx = collect_repo_context(trace_files, EXTRA_CONTEXT_FILES)
        trace_allowlist = build_trace_allowlist(trace_files)

        # Few-shotã‚’çŸ­æ–‡åŒ–
        compact_fs = []
        for ex in fewshots:
            compact_fs.append(
                {
                    "failure": str(ex.get("failure", ""))[:400],
                    "patch": {
                        "path": ex.get("patch", {}).get("path", ""),
                        "why": str(ex.get("patch", {}).get("why", ""))[:200],
                    },
                }
            )

        user_prompt = PROMPT_USER_FMT.format(
            code=0,
            stdout_tail=stdout_tail,
            stderr_tail=stderr_tail,
            ctx_json=json.dumps(ctx, ensure_ascii=False)[:CTX_MAX_BYTES],
            fingerprints_json=json.dumps(fps, ensure_ascii=False),
            fewshots_json=json.dumps(compact_fs, ensure_ascii=False),
            allowed_dirs=list(ALLOWED_DIRS),
        )

        proposal = call_model(user_prompt)
        reason = proposal.get("reason", "")
        patch_list = proposal.get("patches", [])
        print(f"[model] reason: {reason}")
        print(f"[model] num patches: {len(patch_list)}")

        valid, errs = validate_patches(patch_list, required_tokens, allowed_paths=trace_allowlist)
        if errs:
            print("! patch validation errors:")
            for e in errs:
                print("  -", e)
        if not valid:
            print("No valid patches; stopping.")
            log_metrics(
                {
                    "ts": int(time.time()),
                    "iter": it,
                    "result": "NO_VALID_PATCH",
                    "model": MODEL,
                    "errors": errs[-10:],
                }
            )
            sys.exit(2)

        # ===== å›å¸°ã‚²ãƒ¼ãƒˆï¼šé©ç”¨ â†’ æ•´å½¢ â†’ å·®åˆ†ãƒ†ã‚¹ãƒˆ â†’ å¤±æ•—ãªã‚‰ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ =====
        applied = apply_patches_with_backups(valid)
        try:
            format_code()

            # å·®åˆ†ãƒ†ã‚¹ãƒˆ
            target_tests = detect_changed_tests_from_patches(valid)
            start_ts3 = time.time()
            res_diff = run_pytest(light=True, target_tests=target_tests or None)
            diff_elapsed = time.time() - start_ts3

            if not res_diff.ok:
                print("âš ï¸ Diff tests still failing; rolling back this iteration.")
                log_metrics(
                    {
                        "ts": int(time.time()),
                        "iter": it,
                        "result": "DIFF_FAIL",
                        "model": MODEL,
                        "patch_count": len(valid),
                        "diff_elapsed_sec": round(diff_elapsed, 3),
                        "target_tests": target_tests,
                    }
                )
                rollback_files(applied)
                continue

            # è»½ãƒ†ã‚¹ãƒˆå…¨ä½“
            res_light2 = run_pytest(light=True)
            if not res_light2.ok:
                print("âš ï¸ Light tests failed after patch; rolling back.")
                log_metrics(
                    {
                        "ts": int(time.time()),
                        "iter": it,
                        "result": "LIGHT_FAIL",
                        "model": MODEL,
                        "patch_count": len(valid),
                    }
                )
                rollback_files(applied)
                continue

            # é‡ãƒ†ã‚¹ãƒˆï¼ˆå¿…è¦ãªã‚‰ï¼‰
            green = True
            if LIGHT_FIRST:
                res_heavy2 = run_pytest(light=False)
                if not res_heavy2.ok:
                    print("âš ï¸ Heavy tests failed after patch; rolling back.")
                    log_metrics(
                        {
                            "ts": int(time.time()),
                            "iter": it,
                            "result": "HEAVY_FAIL",
                            "model": MODEL,
                            "patch_count": len(valid),
                        }
                    )
                    rollback_files(applied)
                    green = False

            if not green:
                continue

            # ã“ã“ã¾ã§æ¥ãŸã‚‰æˆåŠŸï¼šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æƒé™¤ï¼†ã‚³ãƒŸãƒƒãƒˆ
            finalize_backups(applied)
            if GIT_COMMIT:
                git_commit("autofix: apply model patches (green)")

            print("âœ… GREEN â€” all tests passed after patch.")
            log_metrics(
                {
                    "ts": int(time.time()),
                    "iter": it,
                    "result": "GREEN_AFTER_PATCH",
                    "model": MODEL,
                    "patch_count": len(valid),
                }
            )
            return

        except Exception as e:
            print(f"âš ï¸ Exception during apply/test: {e}; rolling back.")
            rollback_files(applied)
            continue

    print("ğŸ›‘ Iteration budget exceeded without turning GREEN.")
    log_metrics(
        {"ts": int(time.time()), "iter": MAX_ITERS, "result": "BUDGET_EXCEEDED", "model": MODEL}
    )
    sys.exit(1)


if __name__ == "__main__":
    main()
