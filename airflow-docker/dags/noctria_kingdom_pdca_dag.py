from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.utils.dates import days_ago

with DAG(
    dag_id="noctria_kingdom_pdca_dag",
    description="ðŸ° Noctria Kingdomã®PDCAã‚µã‚¤ã‚¯ãƒ«çµ±åˆDAGï¼ˆOptunaæœ€é©åŒ–â†’MetaAIå†å­¦ç¿’â†’é©ç”¨ï¼‰",
    schedule_interval=None,
    start_date=days_ago(1),
    catchup=False,
    tags=["noctria", "kingdom", "pdca"]
) as dag:

    # ðŸ” æœ€é©åŒ–ãƒ¯ãƒ¼ã‚«ãƒ¼
    optimize_worker_1 = BashOperator(
        task_id="optimize_worker_1",
        bash_command="python3 /opt/airflow/scripts/optimize_params_with_optuna.py"
    )

    # âœ… best_params.json ã®çµæžœã‚’ MetaAI ã«é©ç”¨ã—å†å­¦ç¿’
    apply_to_metaai = BashOperator(
        task_id="apply_best_params_to_metaai",
        bash_command="python3 /opt/airflow/scripts/apply_best_params_to_metaai.py"
    )

    # âœ… æœ€çµ‚çš„ã«çŽ‹å›½ã‚·ã‚¹ãƒ†ãƒ ã¸åæ˜ 
    apply_to_kingdom = BashOperator(
        task_id="apply_best_params_to_kingdom",
        bash_command="python3 /opt/airflow/scripts/apply_best_params.py"
    )

    # DAGã®æµã‚Œ: æœ€é©åŒ– â†’ MetaAIå†å­¦ç¿’ â†’ é©ç”¨
    optimize_worker_1 >> apply_to_metaai >> apply_to_kingdom
