from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.utils.dates import days_ago

default_args = {
    'owner': 'noctria_kingdom',
    'depends_on_past': False,
    'email_on_failure': False,
}

with DAG(
    dag_id='noctria_kingdom_pdca',
    default_args=default_args,
    description='ğŸ‘‘ Noctria Kingdom AIã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒˆãƒ¬ãƒ¼ãƒ€ãƒ¼ã®è‡ªå‹•PDCAã‚µã‚¤ã‚¯ãƒ«',
    schedule_interval='@daily',  # ä¾‹: æ¯æ—¥å®Ÿè¡Œ
    start_date=days_ago(1),
    catchup=False,
) as dag:

    # 1ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»æ•´å½¢
    fetch_data = BashOperator(
        task_id='fetch_data',
        bash_command='echo "ğŸ‘‘ ç‹: Aurusã€Prometheusã‚ˆã€æƒ…å ±åé›†ã›ã‚ˆï¼" && python3 /opt/airflow/scripts/fetch_and_clean_fundamentals.py',
    )

    # 2ï¸âƒ£ AIå­¦ç¿’
    train_ai = BashOperator(
        task_id='train_ai',
        bash_command='echo "âš”ï¸ Aurus: æˆ¦ç•¥AIå­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™ï¼" && python3 /opt/airflow/scripts/meta_ai_tensorboard_train.py',
    )

    # 3ï¸âƒ£ æˆ¦ç•¥æˆæœã®åˆ†æ
    analyze_results = BashOperator(
        task_id='analyze_results',
        bash_command='echo "ğŸ›¡ï¸ Noctus: æˆ¦ç•¥ã®å¥å…¨æ€§ã‚’åˆ†æã—ã¾ã™ï¼" && python3 /opt/airflow/scripts/analyze_results.py',
    )

    # 4ï¸âƒ£ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
    optimize_params = BashOperator(
        task_id='optimize_params',
        bash_command='echo "ğŸ”® Prometheus: æœªæ¥äºˆæ¸¬ã«åŸºã¥ãæœ€é©åŒ–ã‚’é€²ã‚ã¾ã™ï¼" && python3 /opt/airflow/scripts/optimize_params.py',
    )

    # 5ï¸âƒ£ æœ€é©åŒ–çµæœã‚’å³æ™‚é©ç”¨
    apply_best_params = BashOperator(
        task_id='apply_best_params',
        bash_command='echo "âš¡ Levia: æœ€é©åŒ–å†…å®¹ã‚’å³æ™‚åæ˜ ï¼" && python3 /opt/airflow/scripts/apply_best_params.py',
    )

    # ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œé †åº
    fetch_data >> train_ai >> analyze_results >> optimize_params >> apply_best_params
