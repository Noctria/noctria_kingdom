# airflow_docker/docker-compose.yaml

x-airflow-common: &airflow-common
  build:
    context: ..                                  # 実行ディレクトリ: airflow_docker/
    dockerfile: ./airflow_docker/docker/Dockerfile
  image: noctria-airflow:latest
  env_file:
    - ../.env            # ルートの .env（共通設定）
    - ./.env             # airflow_docker 専用の .env（FERNET 等）
  environment:
    # ---- Airflow core ----
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__CORE__LOAD_EXAMPLES=False
    - AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT=180
    - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False
    - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER:-airflow}:${POSTGRES_PASSWORD:-airflow}@postgres/${POSTGRES_DB:-airflow}
    - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW_WEBSERVER_SECRET_KEY:-YourSecretKeyForWebServerSession}

    # ---- Observability（まずは stdout 運用）----
    - NOCTRIA_OBS_MODE=stdout
    # ルート .env に DSN があっても拾わないよう、明示的に上書き無効化
    - NOCTRIA_OBS_PG_DSN=
    # DB に書く場合は上の2行を調整し、下の DSN を有効化（Compose の ${...} 展開を利用）
    # - NOCTRIA_OBS_MODE=
    # - NOCTRIA_OBS_PG_DSN=postgresql://${POSTGRES_USER:-airflow}:${POSTGRES_PASSWORD:-airflow}@postgres:5432/${POSTGRES_DB:-airflow}

    # ---- API 認証バックエンド（Basic + session を明示）----
    - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session

    # ---- Python path so that "from src...." works everywhere ----
    - PYTHONPATH=/opt/airflow/src:/opt/airflow

    # ---- Optuna RDB storage (DAG側で上書き可) ----
    - OPTUNA_STORAGE=postgresql+psycopg2://${POSTGRES_USER:-airflow}:${POSTGRES_PASSWORD:-airflow}@postgres:5432/${OPTUNA_DB:-optuna}

    # ---- Prometheus 環境設定（学習DAG用）----
    - PROMETHEUS_ENV=src.envs.noctria_fx_trading_env:NoctriaFXTradingEnv
    - 'PROMETHEUS_ENV_KWARGS={"window":128,"fee":0.0002,"reward_mode":"pnl","max_episode_steps":200,"obs_dim":8}'
    - TOTAL_TIMESTEPS=10000

    # ---- Noctria標準観測次元（8に統一）----
    - NOCTRIA_ENV_OBS_DIM=8
  volumes:
    - ./dags:/opt/airflow/dags
    - ./plugins:/opt/airflow/plugins
    - ../src:/opt/airflow/src
    - ../data:/opt/airflow/data
    - airflow-logs:/opt/airflow/logs         # logs を永続化
  depends_on:
    postgres:
      condition: service_healthy
  restart: always

services:
  postgres:
    image: postgres:13
    container_name: noctria_postgres
    env_file:
      - ../.env
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-airflow}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-airflow}
      - POSTGRES_DB=${POSTGRES_DB:-airflow}
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER:-airflow}"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: always

  airflow-webserver:
    <<: *airflow-common
    container_name: noctria_airflow_webserver
    command: >
      bash -lc "
        airflow db upgrade &&
        # 既定の管理ユーザー（GUIログイン用）
        airflow users create
          --username ${AIRFLOW_USERNAME:-admin}
          --password ${AIRFLOW_PASSWORD:-admin}
          --firstname Noctria
          --lastname King
          --role Admin
          --email admin@noctria.com || true;
        # API 用ユーザー（GUI→Airflow RESTで利用：環境変数で上書き可）
        airflow users create
          --username ${AIRFLOW_API_USERNAME:-airflow}
          --password ${AIRFLOW_API_PASSWORD:-airflow}
          --firstname Api
          --lastname Client
          --role Admin
          --email api@noctria.com || true;
        exec airflow webserver
      "
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  airflow-scheduler:
    <<: *airflow-common
    container_name: noctria_airflow_scheduler
    command: bash -lc "exec airflow scheduler"
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname \"$${HOSTNAME}\""]
      interval: 30s
      timeout: 10s
      retries: 5

volumes:
  postgres-db-volume:
    driver: local
  airflow-logs:
    driver: local
