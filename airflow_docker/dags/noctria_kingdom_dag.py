#!/usr/bin/env python3
# coding: utf-8

"""
ðŸ‘‘ Noctria Kingdom Royal Council DAG (v2.2 confå¯¾å¿œ)
- å®šæœŸçš„ã«å¾¡å‰ä¼šè­°ã‚’è‡ªå‹•é–‹å‚¬ã—ã€çŽ‹å›½ã®æœ€çµ‚çš„ãªæ„æ€æ±ºå®šã‚’è¡Œã†ãŸã‚ã®çµ±åˆDAGã€‚
- å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã®è¦³æ¸¬ã‹ã‚‰ã€çŽ‹å‘½ã®ä¸‹é”ã¾ã§ã‚’ä¸€æ°—é€šè²«ã§å®Ÿè¡Œã™ã‚‹ã€‚
- GUI/RESTã‹ã‚‰ã®æ‰‹å‹•ãƒˆãƒªã‚¬ãƒ¼æ™‚ã€confï¼ˆç†ç”±ãªã©ï¼‰ã‚‚å…¨ã‚¿ã‚¹ã‚¯ã§å—ä¿¡å¯èƒ½ã€‚
"""

import logging
import json
import sys
import os
from datetime import datetime, timedelta
import pandas as pd
import numpy as np

from airflow.models.dag import DAG
from airflow.operators.python import PythonOperator

project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from src.core.path_config import LOGS_DIR
from src.core.data_loader import MarketDataFetcher
from src.core.king_noctria import KingNoctria

default_args = {
    'owner': 'KingNoctria',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

with DAG(
    dag_id='noctria_kingdom_royal_council_dag',
    default_args=default_args,
    description='å¸‚å ´ã‚’è¦³æ¸¬ã—ã€å¾¡å‰ä¼šè­°ã‚’é–‹ãã€çŽ‹ã®æœ€çµ‚åˆ¤æ–­ã‚’ä¸‹ã™ãŸã‚ã®ä¸­å¿ƒçš„ãªDAG',
    schedule_interval=timedelta(hours=1),
    start_date=datetime(2025, 7, 1),
    catchup=False,
    tags=['noctria', 'kingdom', 'royal_council']
) as dag:

    # --- ã‚¿ã‚¹ã‚¯1: å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã®è¦³æ¸¬ ---
    def fetch_market_data_task(**kwargs):
        logger = logging.getLogger("MarketObserver")
        # confå–å¾—
        conf = kwargs.get("dag_run").conf if kwargs.get("dag_run") else {}
        reason = conf.get("reason", "ç†ç”±æœªæŒ‡å®š")
        logger.info(f"ã€å¸‚å ´è¦³æ¸¬ãƒ»ç™ºä»¤ç†ç”±ã€‘{reason}")

        # ãƒ€ãƒŸãƒ¼å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        dummy_hist_data = pd.DataFrame({
            'Close': np.random.normal(loc=150, scale=2, size=100)
        })
        dummy_hist_data['returns'] = dummy_hist_data['Close'].pct_change().dropna()

        market_data = {
            "price": 150.50 + np.random.randn(),
            "previous_price": 150.48 + np.random.randn(),
            "volume": np.random.randint(100, 300),
            "volatility": np.random.uniform(0.1, 0.3),
            "sma_5_vs_20_diff": np.random.uniform(-0.1, 0.1),
            "macd_signal_diff": np.random.uniform(-0.05, 0.05),
            "trend_strength": np.random.uniform(0.3, 0.8),
            "trend_prediction": np.random.choice(["bullish", "bearish", "neutral"]),
            "rsi_14": np.random.uniform(30, 70),
            "stoch_k": np.random.uniform(20, 80),
            "momentum": np.random.uniform(0.4, 0.9),
            "bollinger_upper_dist": np.random.uniform(-0.05, 0.05),
            "bollinger_lower_dist": np.random.uniform(-0.05, 0.05),
            "sentiment": np.random.uniform(0.3, 0.9),
            "order_block": np.random.uniform(0.2, 0.8),
            "liquidity_ratio": np.random.uniform(0.8, 1.5),
            "symbol": "USDJPY",
            "interest_rate_diff": 0.05,
            "cpi_change_rate": 0.03,
            "news_sentiment_score": np.random.uniform(0.4, 0.8),
            "spread": np.random.uniform(0.01, 0.02),
            "historical_data": dummy_hist_data.to_json()
        }

        logger.info("å¸‚å ´ã®è¦³æ¸¬å®Œäº†ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’å¾¡å‰ä¼šè­°ã«æå‡ºã—ã¾ã™ã€‚")
        kwargs['ti'].xcom_push(key='market_data', value=market_data)
        return market_data

    # --- ã‚¿ã‚¹ã‚¯2: å¾¡å‰ä¼šè­°ã®é–‹å‚¬ ---
    def hold_council_task(**kwargs):
        logger = logging.getLogger("RoyalCouncil")
        conf = kwargs.get("dag_run").conf if kwargs.get("dag_run") else {}
        reason = conf.get("reason", "ç†ç”±æœªæŒ‡å®š")
        logger.info(f"ã€å¾¡å‰ä¼šè­°ãƒ»ç™ºä»¤ç†ç”±ã€‘{reason}")

        ti = kwargs['ti']
        market_data_json = ti.xcom_pull(key='market_data', task_ids='fetch_market_data')

        if not market_data_json:
            logger.error("å¸‚å ´ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã‹ã£ãŸãŸã‚ã€ä¼šè­°ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
            raise ValueError("Market data not found in XComs.")

        market_data = market_data_json
        market_data['historical_data'] = pd.read_json(market_data['historical_data'])

        king = KingNoctria()
        council_report = king.hold_council(market_data)

        logger.info(f"ä¼šè­°ã¯çµ‚äº†ã—ã¾ã—ãŸã€‚çŽ‹ã®æœ€çµ‚åˆ¤æ–­ã¯ã€Ž{council_report['final_decision']}ã€ã§ã™ã€‚")
        kwargs['ti'].xcom_push(key='council_report', value=council_report)
        return council_report

    # --- ã‚¿ã‚¹ã‚¯3: çŽ‹å‘½ã®è¨˜éŒ² ---
    def log_decision_task(**kwargs):
        logger = logging.getLogger("RoyalScribe")
        conf = kwargs.get("dag_run").conf if kwargs.get("dag_run") else {}
        reason = conf.get("reason", "ç†ç”±æœªæŒ‡å®š")
        logger.info(f"ã€çŽ‹å‘½è¨˜éŒ²ãƒ»ç™ºä»¤ç†ç”±ã€‘{reason}")

        ti = kwargs['ti']
        report = ti.xcom_pull(key='council_report', task_ids='hold_council')

        if not report:
            logger.warning("è¨˜éŒ²ã™ã¹ãå ±å‘Šæ›¸ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
            return

        # ç™ºä»¤ç†ç”±ã‚‚è¨˜éŒ²ã«æ®‹ã™
        report['trigger_reason'] = reason

        log_file_path = LOGS_DIR / "kingdom_council_reports" / f"{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}_report.json"
        log_file_path.parent.mkdir(parents=True, exist_ok=True)

        # DataFrameã¯JSONã«ã§ããªã„ãŸã‚ã€ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ãªå½¢å¼ã«å¤‰æ›
        if 'assessments' in report and 'noctus_assessment' in report['assessments']:
            if 'historical_data' in report['assessments']['noctus_assessment']:
                del report['assessments']['noctus_assessment']['historical_data']

        with open(log_file_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=4)

        logger.info(f"çŽ‹å‘½ã‚’å…¬å¼è¨˜éŒ²ã¨ã—ã¦æ›¸åº«ã«ç´ã‚ã¾ã—ãŸ: {log_file_path}")

    task_fetch_data = PythonOperator(
        task_id='fetch_market_data',
        python_callable=fetch_market_data_task,
        provide_context=True
    )

    task_hold_council = PythonOperator(
        task_id='hold_council',
        python_callable=hold_council_task,
        provide_context=True
    )

    task_log_decision = PythonOperator(
        task_id='log_decision',
        python_callable=log_decision_task,
        provide_context=True
    )

    task_fetch_data >> task_hold_council >> task_log_decision
