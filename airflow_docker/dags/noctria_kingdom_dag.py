#!/usr/bin/env python3
# coding: utf-8

"""
ðŸ‘‘ Noctria Kingdom Royal Council DAG (v2.1)
- å®šæœŸçš„ã«å¾¡å‰ä¼šè­°ã‚’è‡ªå‹•é–‹å‚¬ã—ã€çŽ‹å›½ã®æœ€çµ‚çš„ãªæ„æ€æ±ºå®šã‚’è¡Œã†ãŸã‚ã®çµ±åˆDAGã€‚
- å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã®è¦³æ¸¬ã‹ã‚‰ã€çŽ‹å‘½ã®ä¸‹é”ã¾ã§ã‚’ä¸€æ°—é€šè²«ã§å®Ÿè¡Œã™ã‚‹ã€‚
"""

import logging
import json
import sys
import os
from datetime import datetime, timedelta
import pandas as pd
import numpy as np

from airflow.models.dag import DAG
from airflow.operators.python import PythonOperator

# âœ… ä¿®æ­£: AirflowãŒ'src'ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ã‚¹ã«è¿½åŠ 
# ã“ã®DAGãƒ•ã‚¡ã‚¤ãƒ«ãŒç½®ã‹ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®2éšŽå±¤ä¸ŠãŒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆï¼ˆ/opt/airflowï¼‰ã«ãªã‚‹
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# --- çŽ‹å›½ã®åŸºç›¤ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from src.core.path_config import LOGS_DIR
from src.core.data_loader import MarketDataFetcher
from src.core.king_noctria import KingNoctria

# ========================================
# ðŸ‘‘ DAGå…±é€šè¨­å®š
# ========================================
default_args = {
    'owner': 'KingNoctria',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

# ========================================
# ðŸ° Noctria Kingdom å¾¡å‰ä¼šè­°DAG
# ========================================
with DAG(
    dag_id='noctria_kingdom_royal_council_dag',
    default_args=default_args,
    description='å¸‚å ´ã‚’è¦³æ¸¬ã—ã€å¾¡å‰ä¼šè­°ã‚’é–‹ãã€çŽ‹ã®æœ€çµ‚åˆ¤æ–­ã‚’ä¸‹ã™ãŸã‚ã®ä¸­å¿ƒçš„ãªDAG',
    schedule_interval=timedelta(hours=1), # 1æ™‚é–“ã”ã¨ã«å®šä¾‹ä¼šè­°ã‚’é–‹å‚¬
    start_date=datetime(2025, 7, 1),
    catchup=False,
    tags=['noctria', 'kingdom', 'royal_council']
) as dag:

    # --- ã‚¿ã‚¹ã‚¯1: å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã®è¦³æ¸¬ ---
    def fetch_market_data_task(**kwargs):
        """
        å¸‚å ´ã®ç¾çŠ¶ã‚’è¦³æ¸¬ã—ã€å¾¡å‰ä¼šè­°ã«å¿…è¦ãªå…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŽé›†ã™ã‚‹ã€‚
        """
        logger = logging.getLogger("MarketObserver")
        logger.info("çŽ‹å›½ã®å¯†åµãŒå¸‚å ´ã®è¦³æ¸¬ã‚’é–‹å§‹ã—ã¾ã—ãŸâ€¦")
        
        # ã“ã®é–¢æ•°å†…ã§ã€Aurusã‚„NoctusãŒå¿…è¦ã¨ã™ã‚‹å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹
        # MarketDataFetcherã‚’æ‹¡å¼µã—ã€ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã‚„ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºã‚’å–å¾—ã™ã‚‹æƒ³å®š
        
        # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        dummy_hist_data = pd.DataFrame({
            'Close': np.random.normal(loc=150, scale=2, size=100)
        })
        dummy_hist_data['returns'] = dummy_hist_data['Close'].pct_change().dropna()

        market_data = {
            "price": 150.50 + np.random.randn(),
            "previous_price": 150.48 + np.random.randn(),
            "volume": np.random.randint(100, 300),
            "volatility": np.random.uniform(0.1, 0.3),
            "sma_5_vs_20_diff": np.random.uniform(-0.1, 0.1),
            "macd_signal_diff": np.random.uniform(-0.05, 0.05),
            "trend_strength": np.random.uniform(0.3, 0.8),
            "trend_prediction": np.random.choice(["bullish", "bearish", "neutral"]),
            "rsi_14": np.random.uniform(30, 70),
            "stoch_k": np.random.uniform(20, 80),
            "momentum": np.random.uniform(0.4, 0.9),
            "bollinger_upper_dist": np.random.uniform(-0.05, 0.05),
            "bollinger_lower_dist": np.random.uniform(-0.05, 0.05),
            "sentiment": np.random.uniform(0.3, 0.9),
            "order_block": np.random.uniform(0.2, 0.8),
            "liquidity_ratio": np.random.uniform(0.8, 1.5),
            "symbol": "USDJPY",
            "interest_rate_diff": 0.05,
            "cpi_change_rate": 0.03,
            "news_sentiment_score": np.random.uniform(0.4, 0.8),
            "spread": np.random.uniform(0.01, 0.02),
            "historical_data": dummy_hist_data.to_json() # DataFrameã¯JSONæ–‡å­—åˆ—ã«å¤‰æ›
        }
        
        logger.info("å¸‚å ´ã®è¦³æ¸¬å®Œäº†ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’å¾¡å‰ä¼šè­°ã«æå‡ºã—ã¾ã™ã€‚")
        kwargs['ti'].xcom_push(key='market_data', value=market_data)
        return market_data

    # --- ã‚¿ã‚¹ã‚¯2: å¾¡å‰ä¼šè­°ã®é–‹å‚¬ ---
    def hold_council_task(**kwargs):
        """
        çŽ‹ãŒäº”è‡£ã‚’æ‹›é›†ã—ã€å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãæœ€çµ‚åˆ¤æ–­ã‚’ä¸‹ã™ã€‚
        """
        logger = logging.getLogger("RoyalCouncil")
        ti = kwargs['ti']
        market_data_json = ti.xcom_pull(key='market_data', task_ids='fetch_market_data')
        
        if not market_data_json:
            logger.error("å¸‚å ´ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã‹ã£ãŸãŸã‚ã€ä¼šè­°ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
            raise ValueError("Market data not found in XComs.")
            
        # XComã‹ã‚‰å—ã‘å–ã£ãŸJSONæ–‡å­—åˆ—ã‚’DataFrameã«æˆ»ã™
        market_data = market_data_json
        market_data['historical_data'] = pd.read_json(market_data['historical_data'])

        # çŽ‹ã‚’çŽ‰åº§ã«ãŠå‘¼ã³ã™ã‚‹
        king = KingNoctria()
        
        # å¾¡å‰ä¼šè­°ã‚’é–‹å‚¬
        council_report = king.hold_council(market_data)
        
        logger.info(f"ä¼šè­°ã¯çµ‚äº†ã—ã¾ã—ãŸã€‚çŽ‹ã®æœ€çµ‚åˆ¤æ–­ã¯ã€Ž{council_report['final_decision']}ã€ã§ã™ã€‚")
        kwargs['ti'].xcom_push(key='council_report', value=council_report)
        return council_report

    # --- ã‚¿ã‚¹ã‚¯3: çŽ‹å‘½ã®è¨˜éŒ² ---
    def log_decision_task(**kwargs):
        """
        å¾¡å‰ä¼šè­°ã®çµæžœï¼ˆçŽ‹å‘½ï¼‰ã‚’çŽ‹å›½ã®å…¬å¼è¨˜éŒ²ã¨ã—ã¦ä¿å­˜ã™ã‚‹ã€‚
        """
        logger = logging.getLogger("RoyalScribe")
        ti = kwargs['ti']
        report = ti.xcom_pull(key='council_report', task_ids='hold_council')
        
        if not report:
            logger.warning("è¨˜éŒ²ã™ã¹ãå ±å‘Šæ›¸ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
            return

        log_file_path = LOGS_DIR / "kingdom_council_reports" / f"{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}_report.json"
        log_file_path.parent.mkdir(parents=True, exist_ok=True)
        
        # DataFrameã¯JSONã«ã§ããªã„ãŸã‚ã€ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ãªå½¢å¼ã«å¤‰æ›
        if 'assessments' in report and 'noctus_assessment' in report['assessments']:
            if 'historical_data' in report['assessments']['noctus_assessment']:
                del report['assessments']['noctus_assessment']['historical_data']

        with open(log_file_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=4)
            
        logger.info(f"çŽ‹å‘½ã‚’å…¬å¼è¨˜éŒ²ã¨ã—ã¦æ›¸åº«ã«ç´ã‚ã¾ã—ãŸ: {log_file_path}")

    # --- ã‚¿ã‚¹ã‚¯ã®å®šç¾© ---
    task_fetch_data = PythonOperator(
        task_id='fetch_market_data',
        python_callable=fetch_market_data_task,
    )

    task_hold_council = PythonOperator(
        task_id='hold_council',
        python_callable=hold_council_task,
    )
    
    task_log_decision = PythonOperator(
        task_id='log_decision',
        python_callable=log_decision_task,
    )

    # --- ä¾å­˜é–¢ä¿‚ã®å®šç¾© (çŽ‹å›½ã®çµ±æ²»ãƒ•ãƒ­ãƒ¼) ---
    task_fetch_data >> task_hold_council >> task_log_decision
