# [NOCTRIA_CORE_REQUIRED]
# airflow_docker/dags/noctria_kingdom_dag.py
#!/usr/bin/env python3
# coding: utf-8

"""
ðŸ‘‘ Noctria Kingdom Royal Council DAG (Airflow 2.6 äº’æ›ç‰ˆ)
- å¸‚å ´è¦³æ¸¬ â†’ å¾¡å‰ä¼šè­° â†’ çŽ‹å‘½è¨˜éŒ²
- GUI/REST ã® confï¼ˆreason ç­‰ï¼‰ã‚’ kwargs ã‹ã‚‰å—ã‘å–ã‚‹
- get_current_context ã¯ä½¿ã‚ãšã€kwargs ã® context ã‚’å‚ç…§

çµ±åˆãƒã‚¤ãƒ³ãƒˆ:
- trace_id ã®èµ·ç¥¨ã¨XComä¼æ¬
- observability(log_*) ã‚’å„ªå…ˆã—ã€å¤±æ•—æ™‚ã¯STDOUTã¸JSONãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
- ensure_import_path() ã‚’å­˜åœ¨ã™ã‚Œã°å‘¼ã³å‡ºã—
"""

import json
import logging
from datetime import datetime, timedelta

import numpy as np
import pandas as pd
from airflow import DAG
from airflow.operators.python import PythonOperator

# ---- src ãƒ‘ã‚¹ã®å‰æä¸‹ã§ã®æ­£è¦ import ----
from src.core.path_config import LOGS_DIR  # æ—¢å­˜ã®ã¾ã¾åˆ©ç”¨

# --- è¿½åŠ : å®‰å…¨ãª import path ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ï¼ˆå­˜åœ¨ã™ã‚Œã°å‘¼ã³å‡ºã—ï¼‰ -----------------
try:
    from src.core.path_config import ensure_import_path  # type: ignore

    ensure_import_path()  # å¼•æ•°ãªã—ã§ã‚‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è§£æ±ºã™ã‚‹å®Ÿè£…ã‚’æƒ³å®šï¼ˆãªã‘ã‚Œã°å†…éƒ¨ã§ç„¡å®³ã«NO-OPï¼‰
except Exception:
    pass
    # å¤±æ•—ã—ã¦ã‚‚DAGãƒ‘ãƒ¼ã‚¹ã‚’é˜»å®³ã—ãªã„
    pass

# --- è¿½åŠ : observability / trace ã¯é…å»¶å¤±æ•—ã«å‚™ãˆã¦ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ã«æ‰±ã† ---------------
try:
    from src.plan_data import observability as obs  # type: ignore
except Exception:  # observability ãŒç„¡ã„/å£Šã‚Œã¦ã„ã¦ã‚‚é‹è¡Œç¶™ç¶š
    obs = None  # type: ignore

try:
    from src.plan_data import trace as trace_mod  # type: ignore
except Exception:
    trace_mod = None  # type: ignore

default_args = {
    "owner": "KingNoctria",
    "depends_on_past": False,
    "email_on_failure": False,
    "email_on_retry": False,
    "retries": 1,
    "retry_delay": timedelta(minutes=5),
}


# --- è¿½åŠ : è¦³æ¸¬ãƒ­ã‚°ã®è–„ã„ãƒ©ãƒƒãƒ‘ï¼ˆobs å„ªå…ˆã€å¤±æ•—æ™‚ã¯ STDOUT JSONï¼‰ -------------------
def _log(level: str, msg: str, extra: dict | None = None, trace_id: str | None = None) -> None:
    extra = extra or {}
    try:
        if obs is not None:
            if level == "info":
                obs.log_info(msg, extra=extra, trace_id=trace_id)  # type: ignore[attr-defined]
            elif level in ("warn", "warning"):
                obs.log_warn(msg, extra=extra, trace_id=trace_id)  # type: ignore[attr-defined]
            elif level == "error":
                obs.log_error(msg, extra=extra, trace_id=trace_id)  # type: ignore[attr-defined]
            else:
                obs.log_debug(msg, extra=extra, trace_id=trace_id)  # type: ignore[attr-defined]
            return
    except Exception:
        pass
        # fallthrough to stdout

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: JSON ã‚’ stdoutï¼ˆAirflow task logï¼‰ã¸
    print(
        json.dumps(
            {
                "ts": datetime.utcnow().isoformat(),
                "level": level.upper(),
                "msg": msg,
                "trace_id": trace_id,
                "extra": extra,
            },
            ensure_ascii=False,
        )
    )


def _new_trace_id() -> str:
    try:
        if trace_mod is not None and hasattr(trace_mod, "new_trace_id"):
            return trace_mod.new_trace_id()  # type: ignore[attr-defined]
    except Exception:
        pass
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆè¡çªä½Žç¢ºçŽ‡ã§ååˆ†ï¼‰
    return f"trace-{datetime.utcnow().strftime('%Y%m%dT%H%M%S%f')}"


def _serialize_for_json(obj):
    if isinstance(obj, pd.DataFrame):
        return obj.to_dict(orient="records")
    if isinstance(obj, dict):
        return {k: _serialize_for_json(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [_serialize_for_json(x) for x in obj]
    return obj


def _get_reason_from_conf(kwargs) -> str:
    dag_run = kwargs.get("dag_run")
    if dag_run and getattr(dag_run, "conf", None):
        return dag_run.conf.get("reason", "ç†ç”±æœªæŒ‡å®š")
    return "ç†ç”±æœªæŒ‡å®š"


with DAG(
    dag_id="noctria_kingdom_royal_council_dag",
    default_args=default_args,
    description="å¸‚å ´ã‚’è¦³æ¸¬ã—ã€å¾¡å‰ä¼šè­°ã‚’é–‹ãã€çŽ‹ã®æœ€çµ‚åˆ¤æ–­ã‚’ä¸‹ã™ãŸã‚ã®ä¸­å¿ƒDAG",
    schedule_interval=timedelta(hours=1),
    start_date=datetime(2025, 7, 1),
    catchup=False,
    tags=["noctria", "kingdom", "royal_council"],
) as dag:

    def fetch_market_data_task(**kwargs):
        logger = logging.getLogger("MarketObserver")
        logger.setLevel(logging.INFO)

        reason = _get_reason_from_conf(kwargs)
        # trace_id èµ·ç¥¨ï¼ˆã“ã“ã‚’èµ·ç‚¹ã«XComã§ä¼æ¬ï¼‰
        trace_id = _new_trace_id()
        _log("info", "ã€å¸‚å ´è¦³æ¸¬ãƒ»ç™ºä»¤ç†ç”±ã€‘" + str(reason), {"phase": "fetch"}, trace_id)

        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆæœ¬ç•ªã¯ fetcher ã¸ç½®æ›å¯ï¼‰
        dummy_hist = pd.DataFrame({"Close": np.random.normal(loc=150, scale=2, size=100)})
        dummy_hist["returns"] = dummy_hist["Close"].pct_change()

        market_data = {
            "price": float(150.50 + np.random.randn()),
            "previous_price": float(150.48 + np.random.randn()),
            "volume": int(np.random.randint(100, 300)),
            "volatility": float(np.random.uniform(0.1, 0.3)),
            "sma_5_vs_20_diff": float(np.random.uniform(-0.1, 0.1)),
            "macd_signal_diff": float(np.random.uniform(-0.05, 0.05)),
            "trend_strength": float(np.random.uniform(0.3, 0.8)),
            "trend_prediction": str(np.random.choice(["bullish", "bearish", "neutral"])),
            "rsi_14": float(np.random.uniform(30, 70)),
            "stoch_k": float(np.random.uniform(20, 80)),
            "momentum": float(np.random.uniform(0.4, 0.9)),
            "bollinger_upper_dist": float(np.random.uniform(-0.05, 0.05)),
            "bollinger_lower_dist": float(np.random.uniform(-0.05, 0.05)),
            "sentiment": float(np.random.uniform(0.3, 0.9)),
            "order_block": float(np.random.uniform(0.2, 0.8)),
            "liquidity_ratio": float(np.random.uniform(0.8, 1.5)),
            "symbol": "USDJPY",
            "interest_rate_diff": 0.05,
            "cpi_change_rate": 0.03,
            "news_sentiment_score": float(np.random.uniform(0.4, 0.8)),
            "spread": float(np.random.uniform(0.01, 0.02)),
            "historical_data": dummy_hist.to_json(date_format="iso"),
            "trigger_reason": reason,
            # è¿½åŠ : trace_id ã‚’ãƒ‡ãƒ¼ã‚¿ã«åŒæ¢±ï¼ˆä¼šè­°å´ã§åˆ©ç”¨å¯ï¼‰
            "trace_id": trace_id,
        }

        # XCom ã¸æ ¼ç´
        ti = kwargs["ti"]
        ti.xcom_push(key="market_data", value=market_data)
        ti.xcom_push(key="trace_id", value=trace_id)

        _log(
            "info",
            "å¸‚å ´ã®è¦³æ¸¬å®Œäº†ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’å¾¡å‰ä¼šè­°ã«æå‡ºã—ã¾ã™ã€‚",
            {"size": len(dummy_hist)},
            trace_id,
        )
        logger.info("å¸‚å ´ã®è¦³æ¸¬å®Œäº†ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’å¾¡å‰ä¼šè­°ã«æå‡ºã—ã¾ã™ã€‚")
        return market_data

    def hold_council_task(**kwargs):
        # é…å»¶ importï¼ˆDAGãƒ‘ãƒ¼ã‚¹ã‚’è»½ãã™ã‚‹ï¼‰
        from src.core.king_noctria import KingNoctria

        logger = logging.getLogger("RoyalCouncil")
        logger.setLevel(logging.INFO)

        reason = _get_reason_from_conf(kwargs)
        ti = kwargs["ti"]

        # XCom ã‹ã‚‰å—é ˜
        market_data = ti.xcom_pull(key="market_data", task_ids="fetch_market_data")
        trace_id = ti.xcom_pull(key="trace_id", task_ids="fetch_market_data") or _new_trace_id()

        _log("info", "ã€å¾¡å‰ä¼šè­°ãƒ»ç™ºä»¤ç†ç”±ã€‘" + str(reason), {"phase": "council"}, trace_id)

        if not market_data:
            _log("error", "å¸‚å ´ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã‹ã£ãŸãŸã‚ã€ä¼šè­°ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚", None, trace_id)
            logger.error("å¸‚å ´ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã‹ã£ãŸãŸã‚ã€ä¼šè­°ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
            raise ValueError("Market data not found in XComs.")

        # å¾©å…ƒ
        hist_json = market_data.get("historical_data")
        if hist_json:
            try:
                market_data["historical_data"] = pd.read_json(hist_json)
            except Exception as e:
                _log(
                    "warn",
                    "historical_data ã®å¾©å…ƒã«å¤±æ•—ï¼ˆç©ºDFã§ç¶™ç¶šï¼‰",
                    {"error": str(e)},
                    trace_id,
                )
                market_data["historical_data"] = pd.DataFrame()

        # KingNoctria å‘¼ã³å‡ºã—ï¼ˆtrace_id ã¯ market_data ã«å…¥ã£ã¦ã„ã‚‹ãŸã‚ã€å†…éƒ¨ã§æ‹¾ãˆã‚‹è¨­è¨ˆã‚’æƒ³å®šï¼‰
        king = KingNoctria()
        council_report = king.hold_council(market_data)

        # è¿½åŠ : report ã«ã‚‚ trace æƒ…å ±ã‚’æ®‹ã™
        if isinstance(council_report, dict):
            council_report.setdefault("trace_id", trace_id)
            council_report.setdefault("trigger_reason", reason)

        _log(
            "info",
            f"ä¼šè­°çµ‚äº†ã€‚çŽ‹ã®æœ€çµ‚åˆ¤æ–­: {council_report.get('final_decision', 'N/A') if isinstance(council_report, dict) else 'N/A'}",
            {"keys": list(council_report.keys()) if isinstance(council_report, dict) else None},
            trace_id,
        )

        ti.xcom_push(key="council_report", value=council_report)
        return council_report

    def log_decision_task(**kwargs):
        logger = logging.getLogger("RoyalScribe")
        logger.setLevel(logging.INFO)

        reason = _get_reason_from_conf(kwargs)
        ti = kwargs["ti"]

        report = ti.xcom_pull(key="council_report", task_ids="hold_council")
        trace_id = ti.xcom_pull(key="trace_id", task_ids="fetch_market_data") or _new_trace_id()

        if not report:
            _log("warn", "è¨˜éŒ²ã™ã¹ãå ±å‘Šæ›¸ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸã€‚", {"phase": "scribe"}, trace_id)
            logger.warning("è¨˜éŒ²ã™ã¹ãå ±å‘Šæ›¸ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
            return

        # æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ç¶­æŒï¼‹è¿½è¨˜
        if isinstance(report, dict):
            report["trigger_reason"] = reason
            report.setdefault("trace_id", trace_id)

        serializable = _serialize_for_json(report)

        log_file_path = (
            LOGS_DIR
            / "kingdom_council_reports"
            / f"{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}_report.json"
        )
        log_file_path.parent.mkdir(parents=True, exist_ok=True)
        with open(log_file_path, "w", encoding="utf-8") as f:
            json.dump(serializable, f, ensure_ascii=False, indent=4)

        _log("info", "çŽ‹å‘½ã‚’å…¬å¼è¨˜éŒ²ã¨ã—ã¦æ›¸åº«ã«ç´ã‚ã¾ã—ãŸ", {"path": str(log_file_path)}, trace_id)
        logger.info(f"çŽ‹å‘½ã‚’å…¬å¼è¨˜éŒ²ã¨ã—ã¦æ›¸åº«ã«ç´ã‚ã¾ã—ãŸ: {log_file_path}")

    task_fetch_data = PythonOperator(
        task_id="fetch_market_data",
        python_callable=fetch_market_data_task,
        provide_context=True,  # Airflow 2.6ç³»ã§ã‚‚å®‰å…¨ã« kwargs ã‚’æ¸¡ã™
    )

    task_hold_council = PythonOperator(
        task_id="hold_council",
        python_callable=hold_council_task,
        provide_context=True,
    )

    task_log_decision = PythonOperator(
        task_id="log_decision",
        python_callable=log_decision_task,
        provide_context=True,
    )

    task_fetch_data >> task_hold_council >> task_log_decision
