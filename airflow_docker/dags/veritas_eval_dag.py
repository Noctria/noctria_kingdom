import os
import json
import importlib.util
from datetime import datetime, timedelta

from airflow import DAG
from airflow.operators.python import PythonOperator

# è©•ä¾¡é–¢æ•°ã®ä¾å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from core.strategy_optimizer_adjusted import simulate_strategy_adjusted
from core.market_loader import load_market_data  # å¿…è¦ã«å¿œã˜ã¦ä¿®æ­£

default_args = {
    'owner': 'Veritas',
    'depends_on_past': False,
    'start_date': datetime(2025, 6, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 0,
    'retry_delay': timedelta(minutes=2),
}

dag = DAG(
    dag_id='veritas_eval_dag',
    default_args=default_args,
    description='âœ… Veritasç”Ÿæˆæˆ¦ç•¥ã®è©•ä¾¡ãƒ»æ¡ç”¨åˆ¤å®šDAG',
    schedule_interval=None,
    catchup=False,
    tags=['veritas', 'evaluation', 'pdca'],
)

def evaluate_and_adopt_strategies(**kwargs):
    generated_dir = "/noctria_kingdom/strategies/veritas_generated"
    official_dir = "/noctria_kingdom/strategies/official"
    log_path = "/noctria_kingdom/airflow_docker/logs/veritas_eval_result.json"

    os.makedirs(official_dir, exist_ok=True)
    os.makedirs(os.path.dirname(log_path), exist_ok=True)

    market_data = load_market_data("market_data.csv")

    # ãƒ­ã‚°èª­ã¿è¾¼ã¿ or åˆæœŸåŒ–
    if os.path.exists(log_path):
        with open(log_path, "r") as f:
            eval_logs = json.load(f)
    else:
        eval_logs = []

    for filename in os.listdir(generated_dir):
        if filename.endswith(".py"):
            path = os.path.join(generated_dir, filename)
            spec = importlib.util.spec_from_file_location("candidate", path)
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)

            if not hasattr(module, "simulate"):
                print(f"âš ï¸ {filename} ã« simulate() ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                continue

            try:
                final_capital = module.simulate(market_data)
                print(f"ğŸ“ˆ è©•ä¾¡: {filename} âœ è³‡ç”£ {final_capital:,.0f}å††")

                log_entry = {
                    "timestamp": datetime.utcnow().isoformat(),
                    "filename": filename,
                    "final_capital": final_capital,
                    "status": "adopted" if final_capital >= 1050000 else "rejected"
                }

                if final_capital >= 1050000:
                    save_path = os.path.join(official_dir, filename)
                    with open(path, "r") as src, open(save_path, "w") as dst:
                        dst.write(src.read())
                    print(f"âœ… æ¡ç”¨: {filename} ã‚’ official/ ã«ä¿å­˜")
                else:
                    print(f"âŒ ä¸æ¡ç”¨: {filename}")

                eval_logs.append(log_entry)

            except Exception as e:
                print(f"ğŸš« è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {filename} âœ {e}")
                eval_logs.append({
                    "timestamp": datetime.utcnow().isoformat(),
                    "filename": filename,
                    "final_capital": None,
                    "status": f"error: {str(e)}"
                })

    # ãƒ­ã‚°ä¿å­˜
    with open(log_path, "w") as f:
        json.dump(eval_logs, f, indent=2)

with dag:
    evaluate_task = PythonOperator(
        task_id='evaluate_and_adopt_generated_strategies',
        python_callable=evaluate_and_adopt_strategies,
        provide_context=True,
    )
