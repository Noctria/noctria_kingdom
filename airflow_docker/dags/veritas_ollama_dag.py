import os
import requests
import logging
import json
import sys

# ãƒ­ã‚°å‡ºåŠ›è¨­å®šï¼ˆAirflowãƒ­ã‚°ã«å‡ºã™ãŸã‚ï¼‰
logger = logging.getLogger("veritas_ollama")
logger.setLevel(logging.INFO)
handler = logging.StreamHandler(sys.stdout)
handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))
logger.addHandler(handler)

try:
    # ğŸ”§ ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾—
    ollama_host = os.getenv("OLLAMA_HOST", "localhost")
    ollama_port = os.getenv("OLLAMA_PORT", "11434")
    ollama_model = os.getenv("OLLAMA_MODEL", "openhermes")
    ollama_prompt = os.getenv("OLLAMA_PROMPT", "æ¬¡ã®USDJPYæˆ¦ç•¥ã‚’5ã¤è€ƒãˆã¦ãã ã•ã„ã€‚")

    # ğŸŒ API URLã‚’çµ„ã¿ç«‹ã¦
    url = f"http://{ollama_host}:{ollama_port}/api/generate"

    logger.info(f"â–¶ï¸ ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡å…ˆ: {url}")

    # ğŸ“¦ ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
    payload = {
        "model": ollama_model,
        "prompt": ollama_prompt
    }

    response = requests.post(url, json=payload, timeout=20)
    response.raise_for_status()  # HTTPã‚¨ãƒ©ãƒ¼ã‚’ä¾‹å¤–åŒ–

    # âœ… çµæœå‡ºåŠ›ï¼ˆæ•´å½¢ï¼‰
    result = response.json()
    logger.info("âœ… Ollamaå¿œç­”:\n" + json.dumps(result, ensure_ascii=False, indent=2))

except requests.exceptions.RequestException as e:
    logger.error("ğŸš¨ ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—:", exc_info=True)
    raise e

except Exception as e:
    logger.error("ğŸš¨ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼:", exc_info=True)
    raise e
