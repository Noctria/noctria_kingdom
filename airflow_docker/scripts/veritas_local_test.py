#!/usr/bin/env python3
# coding: utf-8

"""
Veritas Local Test Script
ğŸ“ Sorobanä¸Šã§ãƒ¢ãƒ‡ãƒ«ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã‹ç¢ºèªã™ã‚‹ãŸã‚ã®ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# âœ… ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
MODEL_DIR = os.getenv("MODEL_DIR", "/noctria_kingdom/airflow_docker/models/nous-hermes-2")

# âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºï¼‰
PROMPT = "USDJPYã«ã¤ã„ã¦ã€æ¥é€±ã®FXæˆ¦ç•¥ã‚’æ—¥æœ¬èªã§5ã¤ææ¡ˆã—ã¦ãã ã•ã„ã€‚"

def generate_fx_strategy(prompt: str) -> str:
    if not os.path.exists(MODEL_DIR):
        raise FileNotFoundError(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {MODEL_DIR}")

    print(f"ğŸ“¦ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­: {MODEL_DIR}")
    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, local_files_only=True)
    model = AutoModelForCausalLM.from_pretrained(MODEL_DIR, local_files_only=True)

    inputs = tokenizer(prompt, return_tensors="pt").to("cuda" if torch.cuda.is_available() else "cpu")
    model.to(inputs["input_ids"].device)

    print("ğŸ§  æ¨è«–ä¸­...")
    with torch.no_grad():
        outputs = model.generate(inputs["input_ids"], max_new_tokens=300)

    result = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return result


if __name__ == "__main__":
    print("ğŸ‘‘ Veritas Local Test: ãƒ¢ãƒ‡ãƒ«ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã‹ç¢ºèªã—ã¾ã™ã€‚")
    try:
        response = generate_fx_strategy(PROMPT)
        print("âœ… ãƒ¢ãƒ‡ãƒ«å¿œç­”:")
        print("=" * 50)
        print(response)
        print("=" * 50)
    except Exception as e:
        print(f"ğŸš¨ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
