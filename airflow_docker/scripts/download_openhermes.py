from transformers import AutoModelForCausalLM, AutoTokenizer
import os

# ãƒ¢ãƒ‡ãƒ«IDã¨ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
MODEL_ID = "openaccess-ai-collective/openhermes-2.5-mistral-7b"
MODEL_DIR = "/noctria_kingdom/airflow_docker/models/openhermes2.5"

# Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆ.env ã§æ¸¡ã™ï¼‰
HF_TOKEN = os.getenv("HF_TOKEN")

def download():
    if not HF_TOKEN:
        raise ValueError("âŒ HF_TOKEN ãŒæœªè¨­å®šã§ã™ã€‚`.env` ã«è¿½åŠ ã—ã€docker-compose.yaml ã§æ¸¡ã—ã¦ãã ã•ã„ã€‚")

    print(f"ğŸ”½ ãƒ¢ãƒ‡ãƒ«ã‚’ {MODEL_ID} ã‹ã‚‰ {MODEL_DIR} ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")

    model = AutoModelForCausalLM.from_pretrained(MODEL_ID, use_auth_token=HF_TOKEN)
    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_auth_token=HF_TOKEN)

    os.makedirs(MODEL_DIR, exist_ok=True)
    model.save_pretrained(MODEL_DIR)
    tokenizer.save_pretrained(MODEL_DIR)

    print("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")

if __name__ == "__main__":
    download()
