#!/usr/bin/env python3
# coding: utf-8

import os
import sys
sys.path.append('/opt/airflow')  # Docker/Airflowç”¨ã®ãƒ‘ã‚¹

from stable_baselines3 import PPO
from core.meta_ai import MetaAI  # ã‚«ã‚¹ã‚¿ãƒ ç’°å¢ƒ

def main():
    print("ğŸ‘‘ ç‹Noctria: Aurusã‚ˆã€æˆ¦ç•¥å­¦ç¿’ã®ä»»å‹™ã‚’é–‹å§‹ã›ã‚ˆï¼")
    print("âš”ï¸ Aurus: å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã«ã€æˆ¦ç•¥ã‚’å¼·åŒ–å­¦ç¿’ã§ç£¨ãã¾ã™ã€‚")
    print("ğŸ”® Prometheus: å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚‚æ´»ç”¨ã—ã€æœªæ¥ã‚’äºˆè¦‹ã—ã¦åæ˜ ã—ã¾ã™ã€‚")
    print("ğŸ›¡ï¸ Noctus: å­¦ç¿’ä¸­ã®ãƒªã‚¹ã‚¯ã«è­¦æˆ’ã‚’æ€ ã‚‰ã¬ã‚ˆã†ç›£è¦–ã—ã¾ã™ã€‚")
    print("âš¡ Levia: çŸ­æœŸåˆ©ç›Šã®åˆˆã‚Šå–ã‚Šæº–å‚™ã‚‚é€²ã‚ã¦ã„ã¾ã™ï¼")

    # ğŸ¯ å„æˆ¦ç•¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨­å®šï¼ˆä»®ã®Noneï¼‰
    strategy_agents = {
        "Aurus": None,
        "Levia": None,
        "Noctus": None,
        "Prometheus": None
    }

    # âœ… ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã®æŸ”è»ŸåŒ–ï¼ˆç’°å¢ƒå¤‰æ•° or ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    base_data_path = os.environ.get("NOCTRIA_DATA_DIR", "/opt/airflow/data")
    full_data_path = os.path.join(base_data_path, "preprocessed_usdjpy_with_fundamental.csv")

    # ğŸ¯ ã‚«ã‚¹ã‚¿ãƒ å­¦ç¿’ç’°å¢ƒï¼ˆMetaAIï¼‰ã‚’ç”Ÿæˆ
    env = MetaAI(strategy_agents=strategy_agents, data_path=full_data_path)

    # ğŸ¯ TensorBoardãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    tensorboard_logdir = os.environ.get("NOCTRIA_TB_LOG", "/opt/airflow/logs/ppo_tensorboard_logs")
    os.makedirs(tensorboard_logdir, exist_ok=True)

    # ğŸ¯ PPOã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–
    ppo_agent = PPO(
        "MlpPolicy",
        env,
        verbose=1,
        tensorboard_log=tensorboard_logdir
    )

    print("âš”ï¸ Aurus: æˆ¦ç•¥å­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«ã‚’å§‹å‹•ï¼")
    ppo_agent.learn(total_timesteps=50000)
    print("âœ… ç‹Noctria: Aurusã€Prometheusã€Noctusã€Leviaâ€¦ä»»å‹™å®Œäº†ï¼ç‹å›½ã®æˆ¦ç•¥ãŒã•ã‚‰ã«ç£¨ã‹ã‚ŒãŸã€‚")

if __name__ == "__main__":
    main()
